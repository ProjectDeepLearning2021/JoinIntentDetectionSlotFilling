{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXH-dFxty8Hc"
      },
      "source": [
        "# Ejecución de modelo base\n",
        "\n",
        "En este notebook se ha seleccionado como base el trabajo presentado por Bing Liu y Ian Lane denominado Attention-Based Recurrent Neural Network Models for Joint Intent Detection\n",
        "and Slot Filling: https://arxiv.org/pdf/1609.01454.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aeun0YXizAJX"
      },
      "source": [
        "## 1. Librerías a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzeTuLVNV0Nv"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pickle\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kmLtfYvSV0N0"
      },
      "source": [
        "# Se verifica si es que el soporte de CUDA está disponible (para utilizar la GPU\n",
        "# en el cómputo de tensores)\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "USE_CUDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EW6nzfcsV0N1"
      },
      "source": [
        "# Se define función para convertir la sequencia de texto a índices en formato de\n",
        "# tensor con soporte de CUDA\n",
        "def prepare_sequence(seq, to_ix):\n",
        "  # Crea una lista a partir de una secuencia. Para cada palabra de la secuencia \n",
        "  # asigna un índice de acuerdo al diccionario \"to_ix\", ya sea que pertenece o \n",
        "  # no (token desconocido <UNK>)\n",
        "  idxs = list(map(lambda w: to_ix[w] if w in to_ix.keys() else to_ix[\"<UNK>\"], seq))\n",
        "  # Convierte la lista en tensor con soporte de CUDA (si está disponible)\n",
        "  tensor = Variable(torch.LongTensor(idxs)).cuda() if USE_CUDA else Variable(torch.LongTensor(idxs))\n",
        "  return tensor\n",
        "\n",
        "# Se define función para obtener los elementos dentro de las listas de una tupla\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7eJEYcbV0N2"
      },
      "source": [
        "## 2. Carga de los datos y preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwZyaaxQzj6a"
      },
      "source": [
        "El conjunto de entrenamiento se obtiene a partir del siguiente repositorio: https://github.com/yvchen/JointSLU/tree/master/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idnTabKO1JIZ"
      },
      "source": [
        "# Obtenemos únicamente el archivo que se utilizará\n",
        "!curl --remote-name -H --location https://raw.githubusercontent.com/yvchen/JointSLU/master/data/atis-2.train.w-intent.iob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gOg6ptxIV0N2"
      },
      "source": [
        "# Cuando se ejecuta en un entorno local indicar correctamente el path general \n",
        "# del proyecto:\n",
        "# path = r'G:\\Mi unidad\\CLASES\\PUCP\\2.Clases\\Ciclo-II-DL\\Proyecto-DL\\JoinIntentDetectionSlotFilling\\Entregables\\Entregable01\\RNN-for-Joint-NLU-master'\n",
        "# train = open(path+\"\\\\\"+\"\\data\\\\atis-2.train.w-intent.iob\",\"r\").readlines()\n",
        "\n",
        "# Se lee la información del archivo con el corpus de ATIS\n",
        "train = open('atis-2.train.w-intent.iob', 'r').readlines()\n",
        "# Se eliminan los saltos de línea al final de la oración\n",
        "train = [t[:-1] for t in train]\n",
        "# Se obtiene la secuencia de entrada (oraciones en inglés), la secuencia de \n",
        "# salida (secuencia de slots) y la intención relacionada a la secuencia\n",
        "train = [[t.split('\\t')[0].split(' '), t.split('\\t')[1].split(' ')[:-1], t.split('\\t')[1].split(' ')[-1]] for t in train]\n",
        "# Se retiran los tokens de inicio y fin en la secuencia de entrada, el token de \n",
        "# inicio en la secuencia de salida (ya que se encuentra desfasada una posición \n",
        "# respecto a la entrada)\n",
        "train = [[t[0][1:-1],t[1][1:],t[2]] for t in train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rqx2iX5By0zz",
        "outputId": "dc2d0e62-684f-417d-e4fc-0b336f667d4d"
      },
      "source": [
        "train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[['i',\n  'want',\n  'to',\n  'fly',\n  'from',\n  'baltimore',\n  'to',\n  'dallas',\n  'round',\n  'trip'],\n ['O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'B-fromloc.city_name',\n  'O',\n  'B-toloc.city_name',\n  'B-round_trip',\n  'I-round_trip'],\n 'atis_flight']"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JrJuooGFV0N3"
      },
      "source": [
        "# Se obtiene las tuplas de las secuencias de entrada, salida y las intenciones \n",
        "# por separado\n",
        "seq_in, seq_out, intent = list(zip(*train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vbbrItN3V0N3"
      },
      "source": [
        "# Se conforma el vocabulario de las palabras, las etiquetas de los slots y las \n",
        "# etiquetas de las intenciones\n",
        "vocab = set(flatten(seq_in))\n",
        "slot_tag = set(flatten(seq_out))\n",
        "intent_tag = set(intent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "o4BhYgIcV0N4"
      },
      "source": [
        "# Se establece el tamaño máximo de la secuencia\n",
        "LENGTH = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WNJfftp6V0N4"
      },
      "source": [
        "# Se definen listas para almacenar las secuencias de entrada y salida luego del\n",
        "# preprocesamiento para añadir tokens de fin de secuencia y para hacer padding\n",
        "sin = []\n",
        "sout = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NNn_dJ5bV0N4"
      },
      "source": [
        "# Se añade nuevamente el token de fin de secuencia (<EOS>) y se hace padding\n",
        "# hasta completar el tamaño máximo de secuencia\n",
        "for i in range(len(seq_in)):\n",
        "  # Secuencia de entrada\n",
        "  temp = seq_in[i]\n",
        "  if len(temp)<LENGTH:\n",
        "    # Añade el token de fin de secuencia\n",
        "    temp.append('<EOS>')\n",
        "    while len(temp)<LENGTH:\n",
        "      # Completa con token de padding hasta completar tamaño máximo de secuencia\n",
        "      temp.append('<PAD>')\n",
        "  else:\n",
        "    # Trunca la secuencia en el tamaño máximo\n",
        "    temp = temp[:LENGTH]\n",
        "    # Reemplaza el último elemento por el token de fin de secuencia\n",
        "    temp[-1]='<EOS>'\n",
        "  sin.append(temp)\n",
        "  \n",
        "  # Secuencia de salida\n",
        "  temp = seq_out[i]\n",
        "  if len(temp)<LENGTH:\n",
        "    while len(temp)<LENGTH:\n",
        "      # Completa con token de padding hasta completar tamaño máximo de secuencia\n",
        "      temp.append('<PAD>')\n",
        "  else:\n",
        "    # Trunca la secuencia en el tamaño máximo\n",
        "    temp = temp[:LENGTH]\n",
        "    # Reemplaza el último elemento por el token de fin de secuencia\n",
        "    temp[-1]='<EOS>'\n",
        "  sout.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UcaKGEd6V0N5"
      },
      "source": [
        "# Se define un diccionario para mapear las palabras a índices\n",
        "word2index = {'<PAD>': 0, '<UNK>':1, '<SOS>':2, '<EOS>':3}\n",
        "for token in vocab:\n",
        "  if token not in word2index.keys():\n",
        "    word2index[token]=len(word2index)\n",
        "\n",
        "# Se invierte el diccionario (para mapear los índices a palabras)\n",
        "index2word = {v:k for k,v in word2index.items()}\n",
        "\n",
        "# Se define un diccionario para mapear las etiquetas de slots a índices\n",
        "tag2index = {'<PAD>' : 0}\n",
        "for tag in slot_tag:\n",
        "  if tag not in tag2index.keys():\n",
        "    tag2index[tag] = len(tag2index)\n",
        "\n",
        "# Se invierte el diccionario (para mapear los índices a etiquetas de palabras)\n",
        "index2tag = {v:k for k,v in tag2index.items()}\n",
        "\n",
        "# Se define un diccionario para mapear las etiquetas de intenciones a índices\n",
        "intent2index={}\n",
        "for ii in intent_tag:\n",
        "  if ii not in intent2index.keys():\n",
        "    intent2index[ii] = len(intent2index)\n",
        "\n",
        "# Se invierte el diccionario (para mapear los índices a etiquetas de intenciones)\n",
        "index2intent = {v:k for k,v in intent2index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uxvkvDXTV0N5"
      },
      "source": [
        "# Se reconstruye una lista general con las listas de secuencias de entrada, \n",
        "# salida y las intenciones\n",
        "train = list(zip(sin, sout, intent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLA8jfqMV0N5",
        "outputId": "c2958c6d-2b6b-49cd-d123-2e0d621f0c34"
      },
      "source": [
        "train[0][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "'atis_flight'"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aehAHe-qV0N6"
      },
      "source": [
        "# Se define una lista vacía para almacenar los tensores con soporte de CUDA \n",
        "# correspondientes a las secuencias de entrada, salida y las intenciones\n",
        "train_data=[]\n",
        "\n",
        "for tr in train:\n",
        "  # Se usa la función \"prepare_sequence\" para obtener el tensor de entrada con\n",
        "  # soporte de CUDA\n",
        "  temp = prepare_sequence(tr[0], word2index)\n",
        "  temp = temp.view(1,-1)\n",
        "  # Se usa la función \"prepare_sequence\" para obtener el tensor de salida con\n",
        "  # soporte de CUDA\n",
        "  temp2 = prepare_sequence(tr[1], tag2index)\n",
        "  temp2 = temp2.view(1,-1)\n",
        "  # Se usa la función \"prepare_sequence\" para obtener el tensor de intención \n",
        "  # con soporte de CUDA\n",
        "  temp3 = Variable(torch.LongTensor([intent2index[tr[2]]])).cuda() if USE_CUDA else Variable(torch.LongTensor([intent2index[tr[2]]]))\n",
        "  # Almacena los tensores en una lista\n",
        "  train_data.append((temp, temp2, temp3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "C_A1ymkFV0N6"
      },
      "source": [
        "# Se define una función para producir batches aleatorios del conjunto de \n",
        "# entrenamiento \n",
        "def getBatch(batch_size, train_data):\n",
        "  random.shuffle(train_data)\n",
        "  sindex = 0\n",
        "  eindex = batch_size\n",
        "  while eindex < len(train_data):\n",
        "    batch = train_data[sindex:eindex]\n",
        "    temp = eindex\n",
        "    eindex = eindex + batch_size\n",
        "    sindex = temp\n",
        "    \n",
        "    yield batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzNWzwPlV0N6"
      },
      "source": [
        "## 3. Definición del Modelo\n",
        "\n",
        "El modelo a trabajar se basa en una Red Neuronal Recurrente con arquitectura Secuencia a Secuencia o seq2seq. Esta consta de un codificador o encoder que recibe la secuencia de entrada, y de un decodificador o decoder que obtiene la secuencia de salida y la intención correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OJru6PCDV0N6"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  # Función de inicialización\n",
        "  def __init__(self, input_size,embedding_size, hidden_size,batch_size=16 ,n_layers=1):\n",
        "    super(Encoder, self).__init__()\n",
        "    # Se inicializa el tamaño de la secuencia de entrada, el tamaño del vector \n",
        "    # de embedding, el tamaño del vector de estado oculto, el número de capas y \n",
        "    # el tamaño del batch\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.batch_size=batch_size\n",
        "    # Se inicializa la capa de embedding y la capa bidireccional LSTM\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, batch_first=True, bidirectional=True)\n",
        "  \n",
        "  # Función para inicializar los pesos\n",
        "  def init_weights(self):\n",
        "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "        #self.lstm.weight.data.\n",
        "    \n",
        "    def init_hidden(self,input):\n",
        "        hidden = Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n",
        "        context = Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n",
        "        return (hidden,context)\n",
        "     \n",
        "    def forward(self, input,input_masking):\n",
        "        \"\"\"\n",
        "        input : B,T (LongTensor)\n",
        "        input_masking : B,T (PAD 마스킹한 ByteTensor)\n",
        "        \n",
        "        <PAD> 제외한 리얼 Context를 다시 만들어서 아웃풋으로\n",
        "        \"\"\"\n",
        "        \n",
        "        self.hidden = self.init_hidden(input)\n",
        "        \n",
        "        embedded = self.embedding(input)\n",
        "        output, self.hidden = self.lstm(embedded, self.hidden)\n",
        "        \n",
        "        real_context=[]\n",
        "        \n",
        "        for i,o in enumerate(output): # B,T,D\n",
        "            real_length = input_masking[i].data.tolist().count(0) # 실제 길이\n",
        "            real_context.append(o[real_length-1])\n",
        "            \n",
        "        return output, torch.cat(real_context).view(input.size(0),-1).unsqueeze(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPlWktH7V0N7"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self,slot_size,intent_size,embedding_size,hidden_size,batch_size=16,n_layers=1,dropout_p=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.slot_size = slot_size\n",
        "        self.intent_size = intent_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_p = dropout_p\n",
        "        self.embedding_size = embedding_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Define the layers\n",
        "        self.embedding = nn.Embedding(self.slot_size, self.embedding_size) #TODO encoder와 공유하도록 하고 학습되지 않게..\n",
        "\n",
        "        #self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.lstm = nn.LSTM(self.embedding_size+self.hidden_size*2, self.hidden_size, self.n_layers, batch_first=True)\n",
        "        self.attn = nn.Linear(self.hidden_size,self.hidden_size) # Attention\n",
        "        self.slot_out = nn.Linear(self.hidden_size*2, self.slot_size)\n",
        "        self.intent_out = nn.Linear(self.hidden_size*2,self.intent_size)\n",
        "    \n",
        "    def init_weights(self):\n",
        "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "        #self.out.bias.data.fill_(0)\n",
        "        #self.out.weight.data.uniform_(-0.1, 0.1)\n",
        "        #self.lstm.weight.data.\n",
        "    \n",
        "    def Attention(self, hidden, encoder_outputs, encoder_maskings):\n",
        "        \"\"\"\n",
        "        hidden : 1,B,D\n",
        "        encoder_outputs : B,T,D\n",
        "        encoder_maskings : B,T # ByteTensor\n",
        "        \"\"\"\n",
        "        \n",
        "        hidden = hidden.squeeze(0).unsqueeze(2)  # 히든 : (1,배치,차원) -> (배치,차원,1)\n",
        "        \n",
        "        batch_size = encoder_outputs.size(0) # B\n",
        "        max_len = encoder_outputs.size(1) # T\n",
        "        energies = self.attn(encoder_outputs.contiguous().view(batch_size*max_len,-1)) # B*T,D -> B*T,D\n",
        "        energies = energies.view(batch_size,max_len,-1) # B,T,D (배치,타임,차원)\n",
        "        attn_energies = energies.bmm(hidden).transpose(1,2) # B,T,D * B,D,1 --> B,1,T\n",
        "        attn_energies = attn_energies.squeeze(1).masked_fill(encoder_maskings,-1e12) # PAD masking\n",
        "        \n",
        "        alpha = F.softmax(attn_energies) # B,T\n",
        "        alpha = alpha.unsqueeze(1) # B,1,T\n",
        "        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D => B,1,D\n",
        "        \n",
        "        return context # B,1,D\n",
        "    \n",
        "    def init_hidden(self,input):\n",
        "        hidden = Variable(torch.zeros(self.n_layers*1, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2,input.size(0), self.hidden_size))\n",
        "        context = Variable(torch.zeros(self.n_layers*1, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n",
        "        return (hidden,context)\n",
        "    \n",
        "    def forward(self, input,context,encoder_outputs,encoder_maskings,training=True):\n",
        "        \"\"\"\n",
        "        input : B,L(length)\n",
        "        enc_context : B,1,D\n",
        "        \"\"\"\n",
        "        # Get the embedding of the current input word\n",
        "        embedded = self.embedding(input)\n",
        "        hidden = self.init_hidden(input)\n",
        "        decode=[]\n",
        "        aligns = encoder_outputs.transpose(0,1)\n",
        "        length = encoder_outputs.size(1)\n",
        "        for i in range(length): # Input_sequence와 Output_sequence의 길이가 같기 때문..\n",
        "            aligned = aligns[i].unsqueeze(1)# B,1,D\n",
        "            _, hidden = self.lstm(torch.cat((embedded,context,aligned),2), hidden) # input, context, aligned encoder hidden, hidden\n",
        "            \n",
        "            # for Intent Detection\n",
        "            if i==0: \n",
        "                intent_hidden = hidden[0].clone() \n",
        "                intent_context = self.Attention(intent_hidden, encoder_outputs,encoder_maskings) \n",
        "                concated = torch.cat((intent_hidden,intent_context.transpose(0,1)),2) # 1,B,D\n",
        "                intent_score = self.intent_out(concated.squeeze(0)) # B,D\n",
        "\n",
        "            concated = torch.cat((hidden[0],context.transpose(0,1)),2)\n",
        "            score = self.slot_out(concated.squeeze(0))\n",
        "            softmaxed = F.log_softmax(score)\n",
        "            decode.append(softmaxed)\n",
        "            _,input = torch.max(softmaxed,1)\n",
        "            embedded = self.embedding(input.unsqueeze(1))\n",
        "            \n",
        "            # 그 다음 Context Vector를 Attention으로 계산\n",
        "            context = self.Attention(hidden[0], encoder_outputs,encoder_maskings) \n",
        "        # 요고 주의! time-step을 column-wise concat한 후, reshape!!\n",
        "        slot_scores = torch.cat(decode,1)\n",
        "        return slot_scores.view(input.size(0)*length,-1), intent_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQuaG78rV0N8"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WQ6y_5IZV0N8"
      },
      "source": [
        "LEARNING_RATE=0.001\n",
        "EMBEDDING_SIZE=64\n",
        "HIDDEN_SIZE=64\n",
        "BATCH_SIZE=16\n",
        "LENGTH=50\n",
        "STEP_SIZE=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK7ygs1aV0N8"
      },
      "source": [
        "encoder = Encoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE)\n",
        "decoder = Decoder(len(tag2index),len(intent2index),len(tag2index)//3,HIDDEN_SIZE*2)\n",
        "if USE_CUDA:\n",
        "    encoder = encoder.cuda()\n",
        "    decoder = decoder.cuda()\n",
        "    \n",
        "encoder.init_weights()\n",
        "decoder.init_weights()\n",
        "\n",
        "loss_function_1 = nn.CrossEntropyLoss(ignore_index=0)\n",
        "loss_function_2 = nn.CrossEntropyLoss()\n",
        "enc_optim= optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
        "dec_optim = optim.Adam(decoder.parameters(),lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XVnGg0V0N8",
        "outputId": "52ec8334-c1d2-4e39-a11d-b84f1573697e"
      },
      "source": [
        "for step in range(STEP_SIZE):\n",
        "    losses=[]\n",
        "    for i, batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
        "        x,y_1,y_2 = zip(*batch)\n",
        "        x = torch.cat(x)\n",
        "        tag_target = torch.cat(y_1)\n",
        "        intent_target = torch.cat(y_2)\n",
        "        x_mask = torch.cat([Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in x]).view(BATCH_SIZE,-1)\n",
        "        y_1_mask = torch.cat([Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in tag_target]).view(BATCH_SIZE,-1)\n",
        " \n",
        "        encoder.zero_grad()\n",
        "        decoder.zero_grad()\n",
        "\n",
        "        output, hidden_c = encoder(x,x_mask)\n",
        "        start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).cuda().transpose(1,0) if USE_CUDA else Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).transpose(1,0)\n",
        "\n",
        "        tag_score, intent_score = decoder(start_decode,hidden_c,output,x_mask)\n",
        "\n",
        "        loss_1 = loss_function_1(tag_score,tag_target.view(-1))\n",
        "        loss_2 = loss_function_2(intent_score,intent_target)\n",
        "\n",
        "        loss = loss_1+loss_2\n",
        "        losses.append(loss.data.cpu().numpy() if USE_CUDA else loss.data.numpy())\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 5.0)\n",
        "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 5.0)\n",
        "\n",
        "        enc_optim.step()\n",
        "        dec_optim.step()\n",
        "\n",
        "        if i % 100==0:\n",
        "            print(\"Step\",step,\" epoch\",i,\" : \",np.mean(losses))\n",
        "            losses=[]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\program files\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  C:/w/b/windows/pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n",
            "c:\\program files\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "c:\\program files\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:80: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "c:\\program files\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "c:\\program files\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0  epoch 0  :  7.8444486\n",
            "Step 0  epoch 100  :  3.5781395\n",
            "Step 0  epoch 200  :  2.522087\n",
            "Step 1  epoch 0  :  2.1048317\n",
            "Step 1  epoch 100  :  2.0938344\n",
            "Step 1  epoch 200  :  1.9086353\n",
            "Step 2  epoch 0  :  1.2067856\n",
            "Step 2  epoch 100  :  1.5272576\n",
            "Step 2  epoch 200  :  1.2815535\n",
            "Step 3  epoch 0  :  0.639454\n",
            "Step 3  epoch 100  :  0.88654757\n",
            "Step 3  epoch 200  :  0.87075263\n",
            "Step 4  epoch 0  :  1.0357732\n",
            "Step 4  epoch 100  :  0.7157541\n",
            "Step 4  epoch 200  :  0.62163746\n",
            "Step 5  epoch 0  :  0.87197936\n",
            "Step 5  epoch 100  :  0.51565486\n",
            "Step 5  epoch 200  :  0.5225725\n",
            "Step 6  epoch 0  :  0.43649942\n",
            "Step 6  epoch 100  :  0.38958845\n",
            "Step 6  epoch 200  :  0.3824968\n",
            "Step 7  epoch 0  :  0.18320212\n",
            "Step 7  epoch 100  :  0.30506927\n",
            "Step 7  epoch 200  :  0.31775403\n",
            "Step 8  epoch 0  :  0.2351942\n",
            "Step 8  epoch 100  :  0.25957364\n",
            "Step 8  epoch 200  :  0.25716484\n",
            "Step 9  epoch 0  :  0.30014545\n",
            "Step 9  epoch 100  :  0.21838708\n",
            "Step 9  epoch 200  :  0.18892267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcUSyFbV0N9"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Yplv745CV0N9"
      },
      "source": [
        "from data import *\n",
        "from model import Encoder,Decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-VgAh-_V0N9",
        "outputId": "f023e83f-e42d-46be-bfc4-54d26e995555"
      },
      "source": [
        "_,word2index,tag2index,intent2index = preprocessing(path+\"\\\\\"+\"\\data\\\\atis-2.train.w-intent.iob\",60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed_data_path : G:\\Mi unidad\\CLASES\\PUCP\\2.Clases\\Ciclo-II-DL\\Proyecto-DL\\JoinIntentDetectionSlotFilling\\Entregables\\Entregable01\\RNN-for-Joint-NLU-master\\data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RcUdX18iV0N9"
      },
      "source": [
        "index2tag = {v:k for k,v in tag2index.items()}\n",
        "index2intent = {v:k for k,v in intent2index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWGhDfKWV0N9"
      },
      "source": [
        "encoder = Encoder(len(word2index),64,64)\n",
        "decoder = Decoder(len(tag2index),len(intent2index),len(tag2index)//3,64*2)\n",
        "\n",
        "encoder.load_state_dict(torch.load(path + \"\\\\\"+'\\models\\\\jointnlu-encoder.pkl'))\n",
        "decoder.load_state_dict(torch.load(path + \"\\\\\"+'\\models\\\\jointnlu-decoder.pkl'))\n",
        "if USE_CUDA:\n",
        "    encoder = encoder.cuda()\n",
        "    decoder = decoder.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppKBXPQhV0N-"
      },
      "source": [
        "test = open(path+\"\\\\\"+\"\\data\\\\atis-2.train.w-intent.iob\",\"r\").readlines()\n",
        "test = [t[:-1] for t in test]\n",
        "test = [[t.split(\"\\t\")[0].split(\" \"),t.split(\"\\t\")[1].split(\" \")[:-1],t.split(\"\\t\")[1].split(\" \")[-1]] for t in test]\n",
        "test = [[t[0][1:-1],t[1][1:],t[2]] for t in test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa0ADCUMV0N-",
        "outputId": "e23d3ab4-205f-49df-fae6-e28411da0787"
      },
      "source": [
        "index = random.choice(range(len(test)))\n",
        "test_raw = test[index][0]\n",
        "test_in = prepare_sequence(test_raw,word2index)\n",
        "test_mask = Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, test_in.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, test_in.data)))).view(1,-1)\n",
        "start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*1])).cuda().transpose(1,0) if USE_CUDA else Variable(torch.LongTensor([[word2index['<SOS>']]*1])).transpose(1,0)\n",
        "\n",
        "output, hidden_c = encoder(test_in.unsqueeze(0),test_mask.unsqueeze(0))\n",
        "tag_score, intent_score = decoder(start_decode,hidden_c,output,test_mask)\n",
        "\n",
        "v,i = torch.max(tag_score,1)\n",
        "print(\"Input Sentence : \",*test[index][0])\n",
        "print(\"Truth        : \",*test[index][1])\n",
        "print(\"Prediction : \",*list(map(lambda ii:index2tag[ii],i.data.tolist())))\n",
        "v,i = torch.max(intent_score,1)\n",
        "print(\"Truth        : \",test[index][2])\n",
        "print(\"Prediction : \",index2intent[i.data.tolist()[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Sentence :  list all flights from baltimore to philadelphia\n",
            "Truth        :  O O O O B-fromloc.city_name O B-toloc.city_name\n",
            "Prediction :  O O O O B-fromloc.city_name O B-toloc.city_name\n",
            "Truth        :  atis_flight\n",
            "Prediction :  atis_flight\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "G:\\Mi unidad\\CLASES\\PUCP\\2.Clases\\Ciclo-II-DL\\Proyecto-DL\\JoinIntentDetectionSlotFilling\\Entregables\\Entregable01\\RNN-for-Joint-NLU-master\\model.py:94: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  C:/w/b/windows/pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n",
            "  attn_energies = attn_energies.squeeze(1).masked_fill(encoder_maskings,-1e12) # PAD masking\n",
            "G:\\Mi unidad\\CLASES\\PUCP\\2.Clases\\Ciclo-II-DL\\Proyecto-DL\\JoinIntentDetectionSlotFilling\\Entregables\\Entregable01\\RNN-for-Joint-NLU-master\\model.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  alpha = F.softmax(attn_energies) # B,T\n",
            "G:\\Mi unidad\\CLASES\\PUCP\\2.Clases\\Ciclo-II-DL\\Proyecto-DL\\JoinIntentDetectionSlotFilling\\Entregables\\Entregable01\\RNN-for-Joint-NLU-master\\model.py:131: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  softmaxed = F.log_softmax(score)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "tbOaNslmV0N-"
      },
      "source": [
        "# TODO "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifCJxzPV0N-"
      },
      "source": [
        "* LSTM forget gate의 bias 1로 고정\n",
        "* intent decoder의 attention을 독립적인 weight로 구성해보기\n",
        "* log_softmax 안하고 그냥  crossentropy해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PPcfEk7xV0N-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}