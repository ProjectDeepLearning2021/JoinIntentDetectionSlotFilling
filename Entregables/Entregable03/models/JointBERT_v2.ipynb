{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JointBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INnHYuqQi4mc"
      },
      "source": [
        "Se descarga el dataset de ATIS empleado en el modelo de referencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp0Jxr4QGHJ"
      },
      "source": [
        "Este notebook está enfocado en ejecutar la implementación en Pytorch de JointBERT, el cual está presente en la publicación \"BERT for Joint Intent Classification and Slot Filling\". El objetivo de ello es tomar como referencia los resultados obtenidos por otros modelos para emplearlos como punto de comparación cuando se emplea el dataset ATIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3QAgpPl4gBQ",
        "outputId": "bfe467cb-9405-4b8c-e52a-cd5d7bc1447b"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/yvchen/JointSLU/master/data/atis-2.train.w-intent.iob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-24 21:37:54--  https://raw.githubusercontent.com/yvchen/JointSLU/master/data/atis-2.train.w-intent.iob\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 808016 (789K) [text/plain]\n",
            "Saving to: ‘atis-2.train.w-intent.iob’\n",
            "\n",
            "\r          atis-2.tr   0%[                    ]       0  --.-KB/s               \ratis-2.train.w-inte 100%[===================>] 789.08K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-11-24 21:37:54 (16.7 MB/s) - ‘atis-2.train.w-intent.iob’ saved [808016/808016]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSEIMPFNi_Wv"
      },
      "source": [
        "Se clona el modelo JointBERT desde Gthub. Lo utilizaremos como referencia utilizando el dataset ATIS. Este es un modelo con la arquitectura Transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm1OV5SR4zU-",
        "outputId": "7cb0fea0-c16a-45d7-ef9b-1fd344e48396"
      },
      "source": [
        "!git clone https://github.com/monologg/JointBERT.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'JointBERT'...\n",
            "remote: Enumerating objects: 332, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 332 (delta 0), reused 1 (delta 0), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (332/332), 486.33 KiB | 13.51 MiB/s, done.\n",
            "Resolving deltas: 100% (193/193), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzd6uIcjJ_L"
      },
      "source": [
        "Se instalan las dependencias para ejecutar el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOUG_bZy42lS",
        "outputId": "7ce8ce7e-d7f2-4162-d932-8024a8fb16c7"
      },
      "source": [
        "!pip3 install transformers==3.0.2 seqeval==0.0.12 pytorch-crf==0.7.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 31.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 194 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 769 kB 32.8 MB/s \n",
            "\u001b[?25hCollecting seqeval==0.0.12\n",
            "  Downloading seqeval-0.0.12.tar.gz (21 kB)\n",
            "Collecting pytorch-crf==0.7.2\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 36.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12) (2.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7434 sha256=14e9189c8429cff82810812644988f19aa0d3bbe0cc653acdca032d17e846876\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, seqeval, pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2 sacremoses-0.0.46 sentencepiece-0.1.96 seqeval-0.0.12 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQgOUojJjfCE"
      },
      "source": [
        "Se cambia a la carpeta donde se encuentra el código del modelo, y se crea la carpeta donde se guardará el modelo luego durante el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZK80eemnEdL",
        "outputId": "728251d3-d158-420a-ced3-728764739065"
      },
      "source": [
        "% cd JointBERT\n",
        "! mkdir ./new_model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/JointBERT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvi8TZwzjgPS"
      },
      "source": [
        "Se entrena el modelo con un batch size de 32,  5 épocas y con una secuencia de entrada con longitud máxima de 50 palabras (la data para entrenamiento es la misma que la utilizada en el trabajo de referencia). Tambien se indica que cada 50 iteraciones se guarde modelo y cada 100 pasos se realice una validacion con los datos de tipo \"dev\" (data/atis/dev)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAvxZFVJKcyX",
        "outputId": "bbc94c44-3a0a-45e0-b74a-986219d36e73"
      },
      "source": [
        " ! python3 main.py --task atis \\\n",
        "                  --model_type bert \\\n",
        "                  --model_dir atis_model \\\n",
        "                  --do_train \\\n",
        "                  --train_batch_size 32 \\\n",
        "                  --num_train_epochs 5 \\\n",
        "                  --model_dir ./new_model/ \\\n",
        "                  --max_seq_len 50 \\\n",
        "                  --logging_steps 100 \\\n",
        "                  --save_steps 50           "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/25/2021 15:27:42 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpeizg027l\n",
            "\rDownloading:   0% 0.00/232k [00:00<?, ?B/s]\rDownloading: 100% 232k/232k [00:00<00:00, 17.8MB/s]\n",
            "11/25/2021 15:27:42 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/25/2021 15:27:42 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/25/2021 15:27:42 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   LOOKING AT ./data/atis/train\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   Writing example 0 of 4478\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   guid: train-0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   tokens: [CLS] i want to fly from baltimore to dallas round trip [SEP]\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   input_ids: 101 1045 2215 2000 4875 2013 6222 2000 5759 2461 4440 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 73 2 114 98 99 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   guid: train-1\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   tokens: [CLS] round trip fares from baltimore to philadelphia less than 1000 dollars round trip fares from denver to philadelphia less than 1000 dollars round trip fares from pittsburgh to philadelphia less than 1000 dollars [SEP]\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   input_ids: 101 2461 4440 27092 2013 6222 2000 4407 2625 2084 6694 6363 2461 4440 27092 2013 7573 2000 4407 2625 2084 6694 6363 2461 4440 27092 2013 6278 2000 4407 2625 2084 6694 6363 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   slot_labels: 0 98 99 2 2 73 2 114 32 2 58 59 98 99 2 2 73 2 114 32 2 58 59 98 99 2 2 73 2 114 32 2 58 59 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   guid: train-2\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   tokens: [CLS] show me the flights arriving on baltimore on june fourteenth [SEP]\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   input_ids: 101 2265 2033 1996 7599 7194 2006 6222 2006 2238 15276 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 114 2 14 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   guid: train-3\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   tokens: [CLS] what are the flights which depart from san francisco fly to washington via indianapolis and arrive by 9 pm [SEP]\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   input_ids: 101 2054 2024 1996 7599 2029 18280 2013 2624 3799 4875 2000 2899 3081 9506 1998 7180 2011 1023 7610 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 2 73 74 2 2 114 2 103 2 2 25 23 24 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   guid: train-4\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   tokens: [CLS] which airlines fly from boston to washington dc via other cities [SEP]\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   input_ids: 101 2029 7608 4875 2013 3731 2000 2899 5887 3081 2060 3655 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   intent_label: 5 (id = 5)\n",
            "11/25/2021 15:27:42 - INFO - data_loader -   slot_labels: 0 2 2 2 2 73 2 114 117 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:45 - INFO - data_loader -   Saving features into cached file ./data/cached_train_atis_bert-base-uncased_50\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   LOOKING AT ./data/atis/dev\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   Writing example 0 of 500\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: dev-0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] i want to fly from boston at 83 ##8 am and arrive in denver at 111 ##0 in the morning [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 1045 2215 2000 4875 2013 3731 2012 6640 2620 2572 1998 7180 1999 7573 2012 11118 2692 1999 1996 2851 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 73 2 52 0 53 2 2 2 114 2 23 0 2 2 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: dev-1\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] show me all round trip flights between houston and las vegas [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 2265 2033 2035 2461 4440 7599 2090 5395 1998 5869 7136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 98 99 2 2 73 2 114 115 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: dev-2\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] i would like some information on a flight from denver to san francisco on united airlines [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 1045 2052 2066 2070 2592 2006 1037 3462 2013 7573 2000 2624 3799 2006 2142 7608 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 2 2 2 73 2 114 115 2 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: dev-3\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] what are the coach flights between dallas and baltimore leaving august tenth and returning august twelve [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 2054 2024 1996 2873 7599 2090 5759 1998 6222 2975 2257 7891 1998 4192 2257 4376 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 29 2 2 73 2 114 2 41 39 2 2 93 92 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: dev-4\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] i ' m flying from boston to the bay area [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 1045 1005 1049 3909 2013 3731 2000 1996 3016 2181 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 0 0 2 2 73 2 2 114 115 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_atis_bert-base-uncased_50\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   LOOKING AT ./data/atis/test\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   Writing example 0 of 893\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: test-0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] i would like to find a flight from charlotte to las vegas that makes a stop in st . louis [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 1045 2052 2066 2000 2424 1037 3462 2013 5904 2000 5869 7136 2008 3084 1037 2644 1999 2358 1012 3434 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 2 2 73 2 114 115 2 2 2 2 2 103 0 104 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: test-1\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] on april first i need a ticket from tacoma to san jose departing before 7 am [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 2006 2258 2034 1045 2342 1037 7281 2013 22954 2000 2624 4560 15971 2077 1021 2572 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 41 39 2 2 2 2 2 73 2 114 115 2 54 52 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: test-2\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] on april first i need a flight going from phoenix to san diego [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 2006 2258 2034 1045 2342 1037 3462 2183 2013 6708 2000 2624 5277 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 41 39 2 2 2 2 2 2 73 2 114 115 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: test-3\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] i would like a flight traveling one way from phoenix to san diego on april first [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 1045 2052 2066 1037 3462 7118 2028 2126 2013 6708 2000 2624 5277 2006 2258 2034 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 98 99 2 73 2 114 115 2 41 39 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   *** Example ***\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   guid: test-4\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   tokens: [CLS] i would like a flight from orlando to salt lake city for april first on delta airlines [SEP]\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   input_ids: 101 1045 2052 2066 1037 3462 2013 10108 2000 5474 2697 2103 2005 2258 2034 2006 7160 7608 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   intent_label: 12 (id = 12)\n",
            "11/25/2021 15:27:46 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 73 2 114 115 115 2 41 39 2 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/25/2021 15:27:47 - INFO - data_loader -   Saving features into cached file ./data/cached_test_atis_bert-base-uncased_50\n",
            "11/25/2021 15:27:47 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_n0cl7c9\n",
            "Downloading: 100% 433/433 [00:00<00:00, 164kB/s]\n",
            "11/25/2021 15:27:47 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/25/2021 15:27:47 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/25/2021 15:27:47 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/25/2021 15:27:47 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"atis\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/25/2021 15:27:47 - INFO - transformers.file_utils -   https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpafcxpaei\n",
            "Downloading: 100% 440M/440M [00:09<00:00, 47.8MB/s]\n",
            "11/25/2021 15:27:56 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/25/2021 15:27:56 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/25/2021 15:27:56 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/25/2021 15:27:59 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing JointBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing JointBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "11/25/2021 15:27:59 - WARNING - transformers.modeling_utils -   Some weights of JointBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "11/25/2021 15:27:59 - INFO - trainer -   ***** Running training *****\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Num examples = 4478\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Num Epochs = 5\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Total train batch size = 32\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Gradient Accumulation steps = 1\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Total optimization steps = 700\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Logging steps = 100\n",
            "11/25/2021 15:27:59 - INFO - trainer -     Save steps = 50\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/140 [00:19<45:24, 19.60s/it]\u001b[A\n",
            "Iteration:   1% 2/140 [00:37<42:13, 18.36s/it]\u001b[A\n",
            "Iteration:   2% 3/140 [00:53<39:39, 17.37s/it]\u001b[A\n",
            "Iteration:   3% 4/140 [01:09<38:10, 16.84s/it]\u001b[A\n",
            "Iteration:   4% 5/140 [01:25<37:15, 16.56s/it]\u001b[A\n",
            "Iteration:   4% 6/140 [01:41<36:35, 16.39s/it]\u001b[A\n",
            "Iteration:   5% 7/140 [01:57<36:07, 16.30s/it]\u001b[A\n",
            "Iteration:   6% 8/140 [02:13<35:42, 16.23s/it]\u001b[A\n",
            "Iteration:   6% 9/140 [02:29<35:18, 16.17s/it]\u001b[A\n",
            "Iteration:   7% 10/140 [02:45<35:00, 16.16s/it]\u001b[A\n",
            "Iteration:   8% 11/140 [03:02<34:54, 16.23s/it]\u001b[A\n",
            "Iteration:   9% 12/140 [03:18<34:34, 16.21s/it]\u001b[A\n",
            "Iteration:   9% 13/140 [03:34<34:16, 16.19s/it]\u001b[A\n",
            "Iteration:  10% 14/140 [03:50<33:58, 16.18s/it]\u001b[A\n",
            "Iteration:  11% 15/140 [04:06<33:44, 16.20s/it]\u001b[A\n",
            "Iteration:  11% 16/140 [04:23<33:30, 16.21s/it]\u001b[A\n",
            "Iteration:  12% 17/140 [04:39<33:16, 16.23s/it]\u001b[A\n",
            "Iteration:  13% 18/140 [04:55<33:03, 16.26s/it]\u001b[A\n",
            "Iteration:  14% 19/140 [05:11<32:39, 16.19s/it]\u001b[A\n",
            "Iteration:  14% 20/140 [05:27<32:18, 16.16s/it]\u001b[A\n",
            "Iteration:  15% 21/140 [05:43<31:56, 16.11s/it]\u001b[A\n",
            "Iteration:  16% 22/140 [05:59<31:41, 16.12s/it]\u001b[A\n",
            "Iteration:  16% 23/140 [06:15<31:21, 16.08s/it]\u001b[A\n",
            "Iteration:  17% 24/140 [06:31<31:02, 16.06s/it]\u001b[A\n",
            "Iteration:  18% 25/140 [06:48<30:47, 16.07s/it]\u001b[A\n",
            "Iteration:  19% 26/140 [07:04<30:32, 16.07s/it]\u001b[A\n",
            "Iteration:  19% 27/140 [07:20<30:16, 16.08s/it]\u001b[A\n",
            "Iteration:  20% 28/140 [07:36<30:00, 16.07s/it]\u001b[A\n",
            "Iteration:  21% 29/140 [07:52<29:43, 16.06s/it]\u001b[A\n",
            "Iteration:  21% 30/140 [08:08<29:30, 16.09s/it]\u001b[A\n",
            "Iteration:  22% 31/140 [08:24<29:13, 16.09s/it]\u001b[A\n",
            "Iteration:  23% 32/140 [08:40<28:56, 16.08s/it]\u001b[A\n",
            "Iteration:  24% 33/140 [08:56<28:40, 16.08s/it]\u001b[A\n",
            "Iteration:  24% 34/140 [09:12<28:25, 16.09s/it]\u001b[A\n",
            "Iteration:  25% 35/140 [09:28<28:08, 16.08s/it]\u001b[A\n",
            "Iteration:  26% 36/140 [09:45<27:56, 16.12s/it]\u001b[A\n",
            "Iteration:  26% 37/140 [10:01<27:44, 16.16s/it]\u001b[A\n",
            "Iteration:  27% 38/140 [10:18<27:55, 16.43s/it]\u001b[A\n",
            "Iteration:  28% 39/140 [10:35<28:09, 16.73s/it]\u001b[A\n",
            "Iteration:  29% 40/140 [10:52<27:37, 16.57s/it]\u001b[A\n",
            "Iteration:  29% 41/140 [11:08<27:09, 16.46s/it]\u001b[A\n",
            "Iteration:  30% 42/140 [11:24<26:44, 16.37s/it]\u001b[A\n",
            "Iteration:  31% 43/140 [11:40<26:19, 16.28s/it]\u001b[A\n",
            "Iteration:  31% 44/140 [11:56<25:59, 16.25s/it]\u001b[A\n",
            "Iteration:  32% 45/140 [12:12<25:40, 16.22s/it]\u001b[A\n",
            "Iteration:  33% 46/140 [12:28<25:22, 16.20s/it]\u001b[A\n",
            "Iteration:  34% 47/140 [12:45<25:05, 16.19s/it]\u001b[A\n",
            "Iteration:  34% 48/140 [13:01<24:50, 16.20s/it]\u001b[A\n",
            "Iteration:  35% 49/140 [13:17<24:35, 16.21s/it]\u001b[A11/25/2021 15:41:33 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 15:41:34 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 15:41:34 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  36% 50/140 [13:35<25:06, 16.74s/it]\u001b[A\n",
            "Iteration:  36% 51/140 [13:51<24:38, 16.61s/it]\u001b[A\n",
            "Iteration:  37% 52/140 [14:08<24:10, 16.48s/it]\u001b[A\n",
            "Iteration:  38% 53/140 [14:24<23:46, 16.40s/it]\u001b[A\n",
            "Iteration:  39% 54/140 [14:40<23:27, 16.36s/it]\u001b[A\n",
            "Iteration:  39% 55/140 [14:57<23:16, 16.43s/it]\u001b[A\n",
            "Iteration:  40% 56/140 [15:13<22:54, 16.36s/it]\u001b[A\n",
            "Iteration:  41% 57/140 [15:29<22:32, 16.29s/it]\u001b[A\n",
            "Iteration:  41% 58/140 [15:45<22:12, 16.25s/it]\u001b[A\n",
            "Iteration:  42% 59/140 [16:01<21:55, 16.24s/it]\u001b[A\n",
            "Iteration:  43% 60/140 [16:17<21:34, 16.19s/it]\u001b[A\n",
            "Iteration:  44% 61/140 [16:34<21:17, 16.18s/it]\u001b[A\n",
            "Iteration:  44% 62/140 [16:50<21:00, 16.16s/it]\u001b[A\n",
            "Iteration:  45% 63/140 [17:06<20:47, 16.20s/it]\u001b[A\n",
            "Iteration:  46% 64/140 [17:22<20:31, 16.20s/it]\u001b[A\n",
            "Iteration:  46% 65/140 [17:38<20:14, 16.19s/it]\u001b[A\n",
            "Iteration:  47% 66/140 [17:55<19:58, 16.20s/it]\u001b[A\n",
            "Iteration:  48% 67/140 [18:11<19:42, 16.20s/it]\u001b[A\n",
            "Iteration:  49% 68/140 [18:27<19:24, 16.17s/it]\u001b[A\n",
            "Iteration:  49% 69/140 [18:43<19:10, 16.20s/it]\u001b[A\n",
            "Iteration:  50% 70/140 [18:59<18:57, 16.24s/it]\u001b[A\n",
            "Iteration:  51% 71/140 [19:16<18:40, 16.24s/it]\u001b[A\n",
            "Iteration:  51% 72/140 [19:32<18:23, 16.23s/it]\u001b[A\n",
            "Iteration:  52% 73/140 [19:48<18:10, 16.28s/it]\u001b[A\n",
            "Iteration:  53% 74/140 [20:05<17:53, 16.26s/it]\u001b[A\n",
            "Iteration:  54% 75/140 [20:21<17:35, 16.24s/it]\u001b[A\n",
            "Iteration:  54% 76/140 [20:39<18:01, 16.90s/it]\u001b[A\n",
            "Iteration:  55% 77/140 [20:55<17:32, 16.71s/it]\u001b[A\n",
            "Iteration:  56% 78/140 [21:12<17:07, 16.57s/it]\u001b[A\n",
            "Iteration:  56% 79/140 [21:28<16:45, 16.48s/it]\u001b[A\n",
            "Iteration:  57% 80/140 [21:44<16:23, 16.40s/it]\u001b[A\n",
            "Iteration:  58% 81/140 [22:00<16:05, 16.37s/it]\u001b[A\n",
            "Iteration:  59% 82/140 [22:17<15:46, 16.32s/it]\u001b[A\n",
            "Iteration:  59% 83/140 [22:33<15:30, 16.32s/it]\u001b[A\n",
            "Iteration:  60% 84/140 [22:49<15:10, 16.25s/it]\u001b[A\n",
            "Iteration:  61% 85/140 [23:05<14:55, 16.29s/it]\u001b[A\n",
            "Iteration:  61% 86/140 [23:22<14:38, 16.27s/it]\u001b[A\n",
            "Iteration:  62% 87/140 [23:38<14:21, 16.25s/it]\u001b[A\n",
            "Iteration:  63% 88/140 [23:54<14:04, 16.25s/it]\u001b[A\n",
            "Iteration:  64% 89/140 [24:10<13:48, 16.25s/it]\u001b[A\n",
            "Iteration:  64% 90/140 [24:27<13:39, 16.39s/it]\u001b[A\n",
            "Iteration:  65% 91/140 [24:43<13:22, 16.38s/it]\u001b[A\n",
            "Iteration:  66% 92/140 [25:00<13:05, 16.36s/it]\u001b[A\n",
            "Iteration:  66% 93/140 [25:16<12:46, 16.31s/it]\u001b[A\n",
            "Iteration:  67% 94/140 [25:32<12:27, 16.26s/it]\u001b[A\n",
            "Iteration:  68% 95/140 [25:48<12:10, 16.23s/it]\u001b[A\n",
            "Iteration:  69% 96/140 [26:04<11:53, 16.22s/it]\u001b[A\n",
            "Iteration:  69% 97/140 [26:21<11:35, 16.18s/it]\u001b[A\n",
            "Iteration:  70% 98/140 [26:37<11:18, 16.15s/it]\u001b[A\n",
            "Iteration:  71% 99/140 [26:53<11:02, 16.15s/it]\u001b[A11/25/2021 15:55:08 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 15:55:08 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 15:55:08 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:06,  9.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:19<00:57,  9.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:47,  9.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:38<00:38,  9.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:47<00:28,  9.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:57<00:19,  9.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:06<00:09,  9.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:14<00:00,  9.28s/it]\n",
            "11/25/2021 15:56:23 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 15:56:23 - INFO - trainer -     intent_acc = 0.904\n",
            "11/25/2021 15:56:23 - INFO - trainer -     loss = 0.7198418006300926\n",
            "11/25/2021 15:56:23 - INFO - trainer -     sementic_frame_acc = 0.546\n",
            "11/25/2021 15:56:23 - INFO - trainer -     slot_f1 = 0.8347058823529412\n",
            "11/25/2021 15:56:23 - INFO - trainer -     slot_precision = 0.8396449704142012\n",
            "11/25/2021 15:56:23 - INFO - trainer -     slot_recall = 0.8298245614035088\n",
            "11/25/2021 15:56:23 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 15:56:24 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 15:56:24 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  71% 100/140 [28:25<25:59, 38.99s/it]\u001b[A\n",
            "Iteration:  72% 101/140 [28:41<20:54, 32.18s/it]\u001b[A\n",
            "Iteration:  73% 102/140 [28:57<17:18, 27.34s/it]\u001b[A\n",
            "Iteration:  74% 103/140 [29:13<14:46, 23.96s/it]\u001b[A\n",
            "Iteration:  74% 104/140 [29:29<12:56, 21.57s/it]\u001b[A\n",
            "Iteration:  75% 105/140 [29:46<11:38, 19.95s/it]\u001b[A\n",
            "Iteration:  76% 106/140 [30:02<10:37, 18.76s/it]\u001b[A\n",
            "Iteration:  76% 107/140 [30:18<09:51, 17.92s/it]\u001b[A\n",
            "Iteration:  77% 108/140 [30:34<09:14, 17.33s/it]\u001b[A\n",
            "Iteration:  78% 109/140 [30:49<08:44, 16.92s/it]\u001b[A\n",
            "Iteration:  79% 110/140 [31:08<08:43, 17.44s/it]\u001b[A\n",
            "Iteration:  79% 111/140 [31:25<08:19, 17.23s/it]\u001b[A\n",
            "Iteration:  80% 112/140 [31:41<07:55, 16.98s/it]\u001b[A\n",
            "Iteration:  81% 113/140 [31:58<07:33, 16.81s/it]\u001b[A\n",
            "Iteration:  81% 114/140 [32:14<07:14, 16.70s/it]\u001b[A\n",
            "Iteration:  82% 115/140 [32:31<06:55, 16.62s/it]\u001b[A\n",
            "Iteration:  83% 116/140 [32:47<06:38, 16.59s/it]\u001b[A\n",
            "Iteration:  84% 117/140 [33:04<06:20, 16.56s/it]\u001b[A\n",
            "Iteration:  84% 118/140 [33:20<06:03, 16.52s/it]\u001b[A\n",
            "Iteration:  85% 119/140 [33:36<05:46, 16.49s/it]\u001b[A\n",
            "Iteration:  86% 120/140 [33:53<05:29, 16.47s/it]\u001b[A\n",
            "Iteration:  86% 121/140 [34:09<05:12, 16.45s/it]\u001b[A\n",
            "Iteration:  87% 122/140 [34:26<04:55, 16.43s/it]\u001b[A\n",
            "Iteration:  88% 123/140 [34:42<04:40, 16.48s/it]\u001b[A\n",
            "Iteration:  89% 124/140 [34:59<04:23, 16.48s/it]\u001b[A\n",
            "Iteration:  89% 125/140 [35:15<04:07, 16.47s/it]\u001b[A\n",
            "Iteration:  90% 126/140 [35:32<03:50, 16.46s/it]\u001b[A\n",
            "Iteration:  91% 127/140 [35:48<03:33, 16.45s/it]\u001b[A\n",
            "Iteration:  91% 128/140 [36:04<03:17, 16.46s/it]\u001b[A\n",
            "Iteration:  92% 129/140 [36:21<03:00, 16.45s/it]\u001b[A\n",
            "Iteration:  93% 130/140 [36:37<02:44, 16.42s/it]\u001b[A\n",
            "Iteration:  94% 131/140 [36:54<02:28, 16.44s/it]\u001b[A\n",
            "Iteration:  94% 132/140 [37:10<02:11, 16.46s/it]\u001b[A\n",
            "Iteration:  95% 133/140 [37:27<01:55, 16.44s/it]\u001b[A\n",
            "Iteration:  96% 134/140 [37:43<01:38, 16.43s/it]\u001b[A\n",
            "Iteration:  96% 135/140 [38:00<01:22, 16.44s/it]\u001b[A\n",
            "Iteration:  97% 136/140 [38:16<01:05, 16.43s/it]\u001b[A\n",
            "Iteration:  98% 137/140 [38:32<00:49, 16.43s/it]\u001b[A\n",
            "Iteration:  99% 138/140 [38:49<00:32, 16.41s/it]\u001b[A\n",
            "Iteration:  99% 139/140 [39:05<00:16, 16.41s/it]\u001b[A\n",
            "Iteration: 100% 140/140 [39:21<00:00, 16.87s/it]\n",
            "Epoch:  20% 1/5 [39:21<2:37:24, 2361.14s/it]\n",
            "Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/140 [00:16<38:03, 16.43s/it]\u001b[A\n",
            "Iteration:   1% 2/140 [00:32<37:51, 16.46s/it]\u001b[A\n",
            "Iteration:   2% 3/140 [00:49<37:33, 16.45s/it]\u001b[A\n",
            "Iteration:   3% 4/140 [01:05<37:12, 16.42s/it]\u001b[A\n",
            "Iteration:   4% 5/140 [01:22<36:59, 16.44s/it]\u001b[A\n",
            "Iteration:   4% 6/140 [01:38<36:41, 16.43s/it]\u001b[A\n",
            "Iteration:   5% 7/140 [01:55<36:25, 16.43s/it]\u001b[A\n",
            "Iteration:   6% 8/140 [02:11<36:04, 16.40s/it]\u001b[A\n",
            "Iteration:   6% 9/140 [02:27<35:46, 16.39s/it]\u001b[A11/25/2021 16:10:04 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 16:10:05 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 16:10:05 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:   7% 10/140 [02:45<36:30, 16.85s/it]\u001b[A\n",
            "Iteration:   8% 11/140 [03:02<35:59, 16.74s/it]\u001b[A\n",
            "Iteration:   9% 12/140 [03:18<35:28, 16.63s/it]\u001b[A\n",
            "Iteration:   9% 13/140 [03:34<35:02, 16.56s/it]\u001b[A\n",
            "Iteration:  10% 14/140 [03:51<34:39, 16.50s/it]\u001b[A\n",
            "Iteration:  11% 15/140 [04:07<34:18, 16.47s/it]\u001b[A\n",
            "Iteration:  11% 16/140 [04:23<33:56, 16.42s/it]\u001b[A\n",
            "Iteration:  12% 17/140 [04:40<33:39, 16.42s/it]\u001b[A\n",
            "Iteration:  13% 18/140 [04:56<33:21, 16.40s/it]\u001b[A\n",
            "Iteration:  14% 19/140 [05:13<33:03, 16.39s/it]\u001b[A\n",
            "Iteration:  14% 20/140 [05:29<32:50, 16.42s/it]\u001b[A\n",
            "Iteration:  15% 21/140 [05:46<32:38, 16.46s/it]\u001b[A\n",
            "Iteration:  16% 22/140 [06:02<32:24, 16.48s/it]\u001b[A\n",
            "Iteration:  16% 23/140 [06:19<32:05, 16.46s/it]\u001b[A\n",
            "Iteration:  17% 24/140 [06:37<32:54, 17.02s/it]\u001b[A\n",
            "Iteration:  18% 25/140 [06:54<32:27, 16.93s/it]\u001b[A\n",
            "Iteration:  19% 26/140 [07:10<31:53, 16.79s/it]\u001b[A\n",
            "Iteration:  19% 27/140 [07:27<31:25, 16.69s/it]\u001b[A\n",
            "Iteration:  20% 28/140 [07:43<31:00, 16.62s/it]\u001b[A\n",
            "Iteration:  21% 29/140 [07:59<30:37, 16.56s/it]\u001b[A\n",
            "Iteration:  21% 30/140 [08:16<30:14, 16.50s/it]\u001b[A\n",
            "Iteration:  22% 31/140 [08:32<29:56, 16.48s/it]\u001b[A\n",
            "Iteration:  23% 32/140 [08:49<29:44, 16.53s/it]\u001b[A\n",
            "Iteration:  24% 33/140 [09:05<29:28, 16.53s/it]\u001b[A\n",
            "Iteration:  24% 34/140 [09:22<29:10, 16.52s/it]\u001b[A\n",
            "Iteration:  25% 35/140 [09:38<28:53, 16.51s/it]\u001b[A\n",
            "Iteration:  26% 36/140 [09:55<28:35, 16.50s/it]\u001b[A\n",
            "Iteration:  26% 37/140 [10:11<28:19, 16.50s/it]\u001b[A\n",
            "Iteration:  27% 38/140 [10:28<28:03, 16.51s/it]\u001b[A\n",
            "Iteration:  28% 39/140 [10:44<27:47, 16.51s/it]\u001b[A\n",
            "Iteration:  29% 40/140 [11:01<27:30, 16.50s/it]\u001b[A\n",
            "Iteration:  29% 41/140 [11:17<27:14, 16.51s/it]\u001b[A\n",
            "Iteration:  30% 42/140 [11:34<26:58, 16.52s/it]\u001b[A\n",
            "Iteration:  31% 43/140 [11:50<26:40, 16.50s/it]\u001b[A\n",
            "Iteration:  31% 44/140 [12:07<26:21, 16.47s/it]\u001b[A\n",
            "Iteration:  32% 45/140 [12:23<26:03, 16.46s/it]\u001b[A\n",
            "Iteration:  33% 46/140 [12:40<25:47, 16.46s/it]\u001b[A\n",
            "Iteration:  34% 47/140 [12:56<25:29, 16.45s/it]\u001b[A\n",
            "Iteration:  34% 48/140 [13:13<25:14, 16.46s/it]\u001b[A\n",
            "Iteration:  35% 49/140 [13:29<24:58, 16.47s/it]\u001b[A\n",
            "Iteration:  36% 50/140 [13:46<24:44, 16.50s/it]\u001b[A\n",
            "Iteration:  36% 51/140 [14:02<24:27, 16.49s/it]\u001b[A\n",
            "Iteration:  37% 52/140 [14:19<24:09, 16.48s/it]\u001b[A\n",
            "Iteration:  38% 53/140 [14:35<23:53, 16.47s/it]\u001b[A\n",
            "Iteration:  39% 54/140 [14:51<23:36, 16.48s/it]\u001b[A\n",
            "Iteration:  39% 55/140 [15:08<23:21, 16.49s/it]\u001b[A\n",
            "Iteration:  40% 56/140 [15:25<23:07, 16.52s/it]\u001b[A\n",
            "Iteration:  41% 57/140 [15:41<22:52, 16.54s/it]\u001b[A\n",
            "Iteration:  41% 58/140 [15:58<22:37, 16.55s/it]\u001b[A\n",
            "Iteration:  42% 59/140 [16:14<22:19, 16.53s/it]\u001b[A11/25/2021 16:23:51 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 16:23:51 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 16:23:51 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:05,  9.35s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:18<00:56,  9.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:46,  9.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:37<00:37,  9.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:46<00:28,  9.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:56<00:18,  9.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:05<00:09,  9.41s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:13<00:00,  9.17s/it]\n",
            "11/25/2021 16:25:05 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 16:25:05 - INFO - trainer -     intent_acc = 0.958\n",
            "11/25/2021 16:25:05 - INFO - trainer -     loss = 0.35764922201633453\n",
            "11/25/2021 16:25:05 - INFO - trainer -     sementic_frame_acc = 0.752\n",
            "11/25/2021 16:25:05 - INFO - trainer -     slot_f1 = 0.9118417224323538\n",
            "11/25/2021 16:25:05 - INFO - trainer -     slot_precision = 0.9073537927041112\n",
            "11/25/2021 16:25:05 - INFO - trainer -     slot_recall = 0.916374269005848\n",
            "11/25/2021 16:25:05 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 16:25:06 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 16:25:06 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  43% 60/140 [17:46<51:59, 39.00s/it]\u001b[A\n",
            "Iteration:  44% 61/140 [18:02<42:30, 32.29s/it]\u001b[A\n",
            "Iteration:  44% 62/140 [18:19<35:46, 27.52s/it]\u001b[A\n",
            "Iteration:  45% 63/140 [18:35<31:03, 24.20s/it]\u001b[A\n",
            "Iteration:  46% 64/140 [18:52<27:42, 21.88s/it]\u001b[A\n",
            "Iteration:  46% 65/140 [19:08<25:18, 20.24s/it]\u001b[A\n",
            "Iteration:  47% 66/140 [19:25<23:33, 19.11s/it]\u001b[A\n",
            "Iteration:  48% 67/140 [19:41<22:17, 18.32s/it]\u001b[A\n",
            "Iteration:  49% 68/140 [19:57<21:19, 17.78s/it]\u001b[A\n",
            "Iteration:  49% 69/140 [20:14<20:36, 17.42s/it]\u001b[A\n",
            "Iteration:  50% 70/140 [20:31<20:02, 17.18s/it]\u001b[A\n",
            "Iteration:  51% 71/140 [20:47<19:31, 16.98s/it]\u001b[A\n",
            "Iteration:  51% 72/140 [21:04<19:03, 16.82s/it]\u001b[A\n",
            "Iteration:  52% 73/140 [21:20<18:43, 16.76s/it]\u001b[A\n",
            "Iteration:  53% 74/140 [21:37<18:21, 16.69s/it]\u001b[A\n",
            "Iteration:  54% 75/140 [21:53<18:02, 16.65s/it]\u001b[A\n",
            "Iteration:  54% 76/140 [22:10<17:42, 16.60s/it]\u001b[A\n",
            "Iteration:  55% 77/140 [22:26<17:23, 16.56s/it]\u001b[A\n",
            "Iteration:  56% 78/140 [22:43<17:04, 16.52s/it]\u001b[A\n",
            "Iteration:  56% 79/140 [22:59<16:48, 16.53s/it]\u001b[A\n",
            "Iteration:  57% 80/140 [23:16<16:30, 16.51s/it]\u001b[A\n",
            "Iteration:  58% 81/140 [23:32<16:17, 16.56s/it]\u001b[A\n",
            "Iteration:  59% 82/140 [23:49<15:59, 16.55s/it]\u001b[A\n",
            "Iteration:  59% 83/140 [24:06<15:43, 16.55s/it]\u001b[A\n",
            "Iteration:  60% 84/140 [24:22<15:25, 16.53s/it]\u001b[A\n",
            "Iteration:  61% 85/140 [24:38<15:08, 16.52s/it]\u001b[A\n",
            "Iteration:  61% 86/140 [24:55<14:50, 16.49s/it]\u001b[A\n",
            "Iteration:  62% 87/140 [25:11<14:34, 16.50s/it]\u001b[A\n",
            "Iteration:  63% 88/140 [25:28<14:18, 16.51s/it]\u001b[A\n",
            "Iteration:  64% 89/140 [25:44<14:01, 16.51s/it]\u001b[A\n",
            "Iteration:  64% 90/140 [26:01<13:45, 16.50s/it]\u001b[A\n",
            "Iteration:  65% 91/140 [26:17<13:27, 16.48s/it]\u001b[A\n",
            "Iteration:  66% 92/140 [26:34<13:11, 16.48s/it]\u001b[A\n",
            "Iteration:  66% 93/140 [26:50<12:53, 16.46s/it]\u001b[A\n",
            "Iteration:  67% 94/140 [27:07<12:36, 16.45s/it]\u001b[A\n",
            "Iteration:  68% 95/140 [27:23<12:21, 16.48s/it]\u001b[A\n",
            "Iteration:  69% 96/140 [27:40<12:06, 16.50s/it]\u001b[A\n",
            "Iteration:  69% 97/140 [27:56<11:50, 16.52s/it]\u001b[A\n",
            "Iteration:  70% 98/140 [28:13<11:32, 16.49s/it]\u001b[A\n",
            "Iteration:  71% 99/140 [28:29<11:15, 16.48s/it]\u001b[A\n",
            "Iteration:  71% 100/140 [28:46<10:59, 16.50s/it]\u001b[A\n",
            "Iteration:  72% 101/140 [29:02<10:43, 16.49s/it]\u001b[A\n",
            "Iteration:  73% 102/140 [29:19<10:26, 16.49s/it]\u001b[A\n",
            "Iteration:  74% 103/140 [29:35<10:10, 16.50s/it]\u001b[A\n",
            "Iteration:  74% 104/140 [29:52<09:53, 16.48s/it]\u001b[A\n",
            "Iteration:  75% 105/140 [30:08<09:37, 16.49s/it]\u001b[A\n",
            "Iteration:  76% 106/140 [30:25<09:20, 16.50s/it]\u001b[A\n",
            "Iteration:  76% 107/140 [30:41<09:04, 16.49s/it]\u001b[A\n",
            "Iteration:  77% 108/140 [30:58<08:46, 16.46s/it]\u001b[A\n",
            "Iteration:  78% 109/140 [31:14<08:29, 16.45s/it]\u001b[A11/25/2021 16:38:51 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 16:38:52 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 16:38:52 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  79% 110/140 [31:32<08:25, 16.86s/it]\u001b[A\n",
            "Iteration:  79% 111/140 [31:48<08:06, 16.77s/it]\u001b[A\n",
            "Iteration:  80% 112/140 [32:07<08:02, 17.23s/it]\u001b[A\n",
            "Iteration:  81% 113/140 [32:23<07:41, 17.10s/it]\u001b[A\n",
            "Iteration:  81% 114/140 [32:40<07:20, 16.93s/it]\u001b[A\n",
            "Iteration:  82% 115/140 [32:57<06:59, 16.79s/it]\u001b[A\n",
            "Iteration:  83% 116/140 [33:13<06:41, 16.71s/it]\u001b[A\n",
            "Iteration:  84% 117/140 [33:30<06:23, 16.67s/it]\u001b[A\n",
            "Iteration:  84% 118/140 [33:46<06:05, 16.62s/it]\u001b[A\n",
            "Iteration:  85% 119/140 [34:03<05:48, 16.60s/it]\u001b[A\n",
            "Iteration:  86% 120/140 [34:19<05:31, 16.56s/it]\u001b[A\n",
            "Iteration:  86% 121/140 [34:36<05:14, 16.54s/it]\u001b[A\n",
            "Iteration:  87% 122/140 [34:52<04:57, 16.52s/it]\u001b[A\n",
            "Iteration:  88% 123/140 [35:09<04:41, 16.54s/it]\u001b[A\n",
            "Iteration:  89% 124/140 [35:25<04:25, 16.58s/it]\u001b[A\n",
            "Iteration:  89% 125/140 [35:42<04:08, 16.58s/it]\u001b[A\n",
            "Iteration:  90% 126/140 [35:58<03:52, 16.57s/it]\u001b[A\n",
            "Iteration:  91% 127/140 [36:15<03:35, 16.56s/it]\u001b[A\n",
            "Iteration:  91% 128/140 [36:32<03:18, 16.56s/it]\u001b[A\n",
            "Iteration:  92% 129/140 [36:48<03:01, 16.54s/it]\u001b[A\n",
            "Iteration:  93% 130/140 [37:05<02:45, 16.53s/it]\u001b[A\n",
            "Iteration:  94% 131/140 [37:21<02:28, 16.52s/it]\u001b[A\n",
            "Iteration:  94% 132/140 [37:38<02:12, 16.51s/it]\u001b[A\n",
            "Iteration:  95% 133/140 [37:54<01:55, 16.55s/it]\u001b[A\n",
            "Iteration:  96% 134/140 [38:11<01:39, 16.53s/it]\u001b[A\n",
            "Iteration:  96% 135/140 [38:27<01:22, 16.52s/it]\u001b[A\n",
            "Iteration:  97% 136/140 [38:44<01:06, 16.51s/it]\u001b[A\n",
            "Iteration:  98% 137/140 [39:00<00:49, 16.54s/it]\u001b[A\n",
            "Iteration:  99% 138/140 [39:17<00:33, 16.55s/it]\u001b[A\n",
            "Iteration:  99% 139/140 [39:33<00:16, 16.58s/it]\u001b[A\n",
            "Iteration: 100% 140/140 [39:49<00:00, 17.07s/it]\n",
            "Epoch:  40% 2/5 [1:19:10<1:58:53, 2377.90s/it]\n",
            "Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/140 [00:16<38:28, 16.61s/it]\u001b[A\n",
            "Iteration:   1% 2/140 [00:33<38:17, 16.65s/it]\u001b[A\n",
            "Iteration:   2% 3/140 [00:49<37:59, 16.64s/it]\u001b[A\n",
            "Iteration:   3% 4/140 [01:06<37:39, 16.61s/it]\u001b[A\n",
            "Iteration:   4% 5/140 [01:23<37:27, 16.65s/it]\u001b[A\n",
            "Iteration:   4% 6/140 [01:39<37:07, 16.63s/it]\u001b[A\n",
            "Iteration:   5% 7/140 [01:56<36:50, 16.62s/it]\u001b[A\n",
            "Iteration:   6% 8/140 [02:12<36:29, 16.59s/it]\u001b[A\n",
            "Iteration:   6% 9/140 [02:29<36:11, 16.58s/it]\u001b[A\n",
            "Iteration:   7% 10/140 [02:46<35:53, 16.57s/it]\u001b[A\n",
            "Iteration:   8% 11/140 [03:02<35:32, 16.53s/it]\u001b[A\n",
            "Iteration:   9% 12/140 [03:18<35:15, 16.53s/it]\u001b[A\n",
            "Iteration:   9% 13/140 [03:35<35:03, 16.56s/it]\u001b[A\n",
            "Iteration:  10% 14/140 [03:52<34:47, 16.56s/it]\u001b[A\n",
            "Iteration:  11% 15/140 [04:08<34:30, 16.57s/it]\u001b[A\n",
            "Iteration:  11% 16/140 [04:25<34:10, 16.54s/it]\u001b[A\n",
            "Iteration:  12% 17/140 [04:41<33:55, 16.55s/it]\u001b[A\n",
            "Iteration:  13% 18/140 [04:58<33:39, 16.55s/it]\u001b[A\n",
            "Iteration:  14% 19/140 [05:15<33:25, 16.58s/it]\u001b[A11/25/2021 16:52:41 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 16:52:41 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 16:52:41 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:07,  9.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:19<00:57,  9.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:47,  9.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:37<00:37,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:47<00:28,  9.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:56<00:18,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:06<00:09,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:13<00:00,  9.24s/it]\n",
            "11/25/2021 16:53:55 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 16:53:55 - INFO - trainer -     intent_acc = 0.964\n",
            "11/25/2021 16:53:55 - INFO - trainer -     loss = 0.2990961018949747\n",
            "11/25/2021 16:53:55 - INFO - trainer -     sementic_frame_acc = 0.818\n",
            "11/25/2021 16:53:55 - INFO - trainer -     slot_f1 = 0.9425754060324826\n",
            "11/25/2021 16:53:55 - INFO - trainer -     slot_precision = 0.9349827387802071\n",
            "11/25/2021 16:53:55 - INFO - trainer -     slot_recall = 0.9502923976608187\n",
            "11/25/2021 16:53:55 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 16:53:57 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 16:53:57 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  14% 20/140 [06:47<1:18:33, 39.28s/it]\u001b[A\n",
            "Iteration:  15% 21/140 [07:03<1:04:28, 32.51s/it]\u001b[A\n",
            "Iteration:  16% 22/140 [07:20<54:34, 27.75s/it]  \u001b[A\n",
            "Iteration:  16% 23/140 [07:37<47:39, 24.44s/it]\u001b[A\n",
            "Iteration:  17% 24/140 [07:54<42:48, 22.14s/it]\u001b[A\n",
            "Iteration:  18% 25/140 [08:10<39:18, 20.51s/it]\u001b[A\n",
            "Iteration:  19% 26/140 [08:27<36:44, 19.34s/it]\u001b[A\n",
            "Iteration:  19% 27/140 [08:44<34:58, 18.57s/it]\u001b[A\n",
            "Iteration:  20% 28/140 [09:00<33:36, 18.00s/it]\u001b[A\n",
            "Iteration:  21% 29/140 [09:17<32:35, 17.61s/it]\u001b[A\n",
            "Iteration:  21% 30/140 [09:34<31:49, 17.36s/it]\u001b[A\n",
            "Iteration:  22% 31/140 [09:51<31:14, 17.20s/it]\u001b[A\n",
            "Iteration:  23% 32/140 [10:07<30:41, 17.05s/it]\u001b[A\n",
            "Iteration:  24% 33/140 [10:24<30:14, 16.96s/it]\u001b[A\n",
            "Iteration:  24% 34/140 [10:41<29:52, 16.91s/it]\u001b[A\n",
            "Iteration:  25% 35/140 [10:58<29:29, 16.85s/it]\u001b[A\n",
            "Iteration:  26% 36/140 [11:14<29:07, 16.81s/it]\u001b[A\n",
            "Iteration:  26% 37/140 [11:31<28:48, 16.78s/it]\u001b[A\n",
            "Iteration:  27% 38/140 [11:48<28:29, 16.76s/it]\u001b[A\n",
            "Iteration:  28% 39/140 [12:04<28:09, 16.73s/it]\u001b[A\n",
            "Iteration:  29% 40/140 [12:21<27:50, 16.71s/it]\u001b[A\n",
            "Iteration:  29% 41/140 [12:38<27:32, 16.70s/it]\u001b[A\n",
            "Iteration:  30% 42/140 [12:54<27:17, 16.71s/it]\u001b[A\n",
            "Iteration:  31% 43/140 [13:11<27:02, 16.73s/it]\u001b[A\n",
            "Iteration:  31% 44/140 [13:28<26:45, 16.72s/it]\u001b[A\n",
            "Iteration:  32% 45/140 [13:45<26:29, 16.73s/it]\u001b[A\n",
            "Iteration:  33% 46/140 [14:01<26:12, 16.73s/it]\u001b[A\n",
            "Iteration:  34% 47/140 [14:18<25:55, 16.73s/it]\u001b[A\n",
            "Iteration:  34% 48/140 [14:35<25:36, 16.71s/it]\u001b[A\n",
            "Iteration:  35% 49/140 [14:51<25:19, 16.70s/it]\u001b[A\n",
            "Iteration:  36% 50/140 [15:08<25:01, 16.68s/it]\u001b[A\n",
            "Iteration:  36% 51/140 [15:25<24:47, 16.71s/it]\u001b[A\n",
            "Iteration:  37% 52/140 [15:42<24:32, 16.74s/it]\u001b[A\n",
            "Iteration:  38% 53/140 [15:58<24:14, 16.72s/it]\u001b[A\n",
            "Iteration:  39% 54/140 [16:16<24:10, 16.87s/it]\u001b[A\n",
            "Iteration:  39% 55/140 [16:35<24:51, 17.55s/it]\u001b[A\n",
            "Iteration:  40% 56/140 [16:51<24:13, 17.30s/it]\u001b[A\n",
            "Iteration:  41% 57/140 [17:08<23:41, 17.12s/it]\u001b[A\n",
            "Iteration:  41% 58/140 [17:25<23:15, 17.02s/it]\u001b[A\n",
            "Iteration:  42% 59/140 [17:42<22:49, 16.91s/it]\u001b[A\n",
            "Iteration:  43% 60/140 [17:58<22:28, 16.85s/it]\u001b[A\n",
            "Iteration:  44% 61/140 [18:15<22:07, 16.80s/it]\u001b[A\n",
            "Iteration:  44% 62/140 [18:32<21:47, 16.76s/it]\u001b[A\n",
            "Iteration:  45% 63/140 [18:48<21:28, 16.74s/it]\u001b[A\n",
            "Iteration:  46% 64/140 [19:05<21:09, 16.71s/it]\u001b[A\n",
            "Iteration:  46% 65/140 [19:22<20:53, 16.71s/it]\u001b[A\n",
            "Iteration:  47% 66/140 [19:38<20:36, 16.71s/it]\u001b[A\n",
            "Iteration:  48% 67/140 [19:55<20:19, 16.71s/it]\u001b[A\n",
            "Iteration:  49% 68/140 [20:12<20:01, 16.69s/it]\u001b[A\n",
            "Iteration:  49% 69/140 [20:28<19:44, 16.69s/it]\u001b[A11/25/2021 17:07:55 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 17:07:57 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 17:07:57 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  50% 70/140 [20:47<20:01, 17.17s/it]\u001b[A\n",
            "Iteration:  51% 71/140 [21:03<19:33, 17.01s/it]\u001b[A\n",
            "Iteration:  51% 72/140 [21:20<19:16, 17.00s/it]\u001b[A\n",
            "Iteration:  52% 73/140 [21:37<18:52, 16.91s/it]\u001b[A\n",
            "Iteration:  53% 74/140 [21:54<18:32, 16.86s/it]\u001b[A\n",
            "Iteration:  54% 75/140 [22:11<18:13, 16.82s/it]\u001b[A\n",
            "Iteration:  54% 76/140 [22:27<17:54, 16.79s/it]\u001b[A\n",
            "Iteration:  55% 77/140 [22:44<17:35, 16.75s/it]\u001b[A\n",
            "Iteration:  56% 78/140 [23:00<17:15, 16.70s/it]\u001b[A\n",
            "Iteration:  56% 79/140 [23:17<16:57, 16.68s/it]\u001b[A\n",
            "Iteration:  57% 80/140 [23:34<16:40, 16.67s/it]\u001b[A\n",
            "Iteration:  58% 81/140 [23:50<16:24, 16.69s/it]\u001b[A\n",
            "Iteration:  59% 82/140 [24:07<16:08, 16.69s/it]\u001b[A\n",
            "Iteration:  59% 83/140 [24:24<15:49, 16.67s/it]\u001b[A\n",
            "Iteration:  60% 84/140 [24:41<15:35, 16.70s/it]\u001b[A\n",
            "Iteration:  61% 85/140 [24:57<15:18, 16.70s/it]\u001b[A\n",
            "Iteration:  61% 86/140 [25:14<15:02, 16.72s/it]\u001b[A\n",
            "Iteration:  62% 87/140 [25:31<14:52, 16.85s/it]\u001b[A\n",
            "Iteration:  63% 88/140 [25:48<14:35, 16.84s/it]\u001b[A\n",
            "Iteration:  64% 89/140 [26:05<14:15, 16.78s/it]\u001b[A\n",
            "Iteration:  64% 90/140 [26:21<13:57, 16.75s/it]\u001b[A\n",
            "Iteration:  65% 91/140 [26:38<13:38, 16.71s/it]\u001b[A\n",
            "Iteration:  66% 92/140 [26:55<13:22, 16.71s/it]\u001b[A\n",
            "Iteration:  66% 93/140 [27:11<13:05, 16.71s/it]\u001b[A\n",
            "Iteration:  67% 94/140 [27:28<12:50, 16.74s/it]\u001b[A\n",
            "Iteration:  68% 95/140 [27:45<12:33, 16.73s/it]\u001b[A\n",
            "Iteration:  69% 96/140 [28:02<12:16, 16.74s/it]\u001b[A\n",
            "Iteration:  69% 97/140 [28:18<11:59, 16.72s/it]\u001b[A\n",
            "Iteration:  70% 98/140 [28:35<11:41, 16.70s/it]\u001b[A\n",
            "Iteration:  71% 99/140 [28:52<11:23, 16.68s/it]\u001b[A\n",
            "Iteration:  71% 100/140 [29:08<11:06, 16.66s/it]\u001b[A\n",
            "Iteration:  72% 101/140 [29:25<10:51, 16.70s/it]\u001b[A\n",
            "Iteration:  73% 102/140 [29:42<10:36, 16.75s/it]\u001b[A\n",
            "Iteration:  74% 103/140 [29:59<10:20, 16.77s/it]\u001b[A\n",
            "Iteration:  74% 104/140 [30:15<10:04, 16.78s/it]\u001b[A\n",
            "Iteration:  75% 105/140 [30:32<09:48, 16.81s/it]\u001b[A\n",
            "Iteration:  76% 106/140 [30:49<09:32, 16.84s/it]\u001b[A\n",
            "Iteration:  76% 107/140 [31:06<09:13, 16.78s/it]\u001b[A\n",
            "Iteration:  77% 108/140 [31:23<08:56, 16.78s/it]\u001b[A\n",
            "Iteration:  78% 109/140 [31:39<08:39, 16.76s/it]\u001b[A\n",
            "Iteration:  79% 110/140 [31:56<08:21, 16.72s/it]\u001b[A\n",
            "Iteration:  79% 111/140 [32:13<08:04, 16.69s/it]\u001b[A\n",
            "Iteration:  80% 112/140 [32:29<07:46, 16.67s/it]\u001b[A\n",
            "Iteration:  81% 113/140 [32:46<07:29, 16.65s/it]\u001b[A\n",
            "Iteration:  81% 114/140 [33:02<07:12, 16.62s/it]\u001b[A\n",
            "Iteration:  82% 115/140 [33:19<06:55, 16.61s/it]\u001b[A\n",
            "Iteration:  83% 116/140 [33:36<06:39, 16.63s/it]\u001b[A\n",
            "Iteration:  84% 117/140 [33:52<06:23, 16.65s/it]\u001b[A\n",
            "Iteration:  84% 118/140 [34:09<06:06, 16.66s/it]\u001b[A\n",
            "Iteration:  85% 119/140 [34:26<05:50, 16.67s/it]\u001b[A11/25/2021 17:21:53 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 17:21:53 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 17:21:53 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:06,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:18<00:56,  9.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:47,  9.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:37<00:37,  9.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:47<00:28,  9.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:57<00:19,  9.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:06<00:09,  9.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:14<00:00,  9.29s/it]\n",
            "11/25/2021 17:23:07 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 17:23:07 - INFO - trainer -     intent_acc = 0.97\n",
            "11/25/2021 17:23:07 - INFO - trainer -     loss = 0.24805354699492455\n",
            "11/25/2021 17:23:07 - INFO - trainer -     sementic_frame_acc = 0.856\n",
            "11/25/2021 17:23:07 - INFO - trainer -     slot_f1 = 0.95781204538842\n",
            "11/25/2021 17:23:07 - INFO - trainer -     slot_precision = 0.9530978575564563\n",
            "11/25/2021 17:23:07 - INFO - trainer -     slot_recall = 0.9625730994152046\n",
            "11/25/2021 17:23:07 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 17:23:08 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 17:23:08 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  86% 120/140 [35:58<13:08, 39.42s/it]\u001b[A\n",
            "Iteration:  86% 121/140 [36:17<10:32, 33.31s/it]\u001b[A\n",
            "Iteration:  87% 122/140 [36:34<08:31, 28.40s/it]\u001b[A\n",
            "Iteration:  88% 123/140 [36:51<07:02, 24.88s/it]\u001b[A\n",
            "Iteration:  89% 124/140 [37:07<05:57, 22.37s/it]\u001b[A\n",
            "Iteration:  89% 125/140 [37:24<05:10, 20.68s/it]\u001b[A\n",
            "Iteration:  90% 126/140 [37:41<04:32, 19.47s/it]\u001b[A\n",
            "Iteration:  91% 127/140 [37:58<04:02, 18.64s/it]\u001b[A\n",
            "Iteration:  91% 128/140 [38:14<03:36, 18.03s/it]\u001b[A\n",
            "Iteration:  92% 129/140 [38:31<03:14, 17.64s/it]\u001b[A\n",
            "Iteration:  93% 130/140 [38:48<02:53, 17.37s/it]\u001b[A\n",
            "Iteration:  94% 131/140 [39:04<02:34, 17.16s/it]\u001b[A\n",
            "Iteration:  94% 132/140 [39:21<02:16, 17.01s/it]\u001b[A\n",
            "Iteration:  95% 133/140 [39:38<01:58, 16.89s/it]\u001b[A\n",
            "Iteration:  96% 134/140 [39:54<01:41, 16.85s/it]\u001b[A\n",
            "Iteration:  96% 135/140 [40:11<01:24, 16.83s/it]\u001b[A\n",
            "Iteration:  97% 136/140 [40:28<01:07, 16.82s/it]\u001b[A\n",
            "Iteration:  98% 137/140 [40:45<00:50, 16.84s/it]\u001b[A\n",
            "Iteration:  99% 138/140 [41:01<00:33, 16.75s/it]\u001b[A\n",
            "Iteration:  99% 139/140 [41:18<00:16, 16.71s/it]\u001b[A\n",
            "Iteration: 100% 140/140 [41:34<00:00, 17.82s/it]\n",
            "Epoch:  60% 3/5 [2:00:44<1:21:02, 2431.01s/it]\n",
            "Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/140 [00:16<38:38, 16.68s/it]\u001b[A\n",
            "Iteration:   1% 2/140 [00:33<38:14, 16.63s/it]\u001b[A\n",
            "Iteration:   2% 3/140 [00:49<37:57, 16.62s/it]\u001b[A\n",
            "Iteration:   3% 4/140 [01:06<37:38, 16.61s/it]\u001b[A\n",
            "Iteration:   4% 5/140 [01:23<37:28, 16.66s/it]\u001b[A\n",
            "Iteration:   4% 6/140 [01:39<37:07, 16.63s/it]\u001b[A\n",
            "Iteration:   5% 7/140 [01:56<36:51, 16.63s/it]\u001b[A\n",
            "Iteration:   6% 8/140 [02:13<36:37, 16.65s/it]\u001b[A\n",
            "Iteration:   6% 9/140 [02:29<36:23, 16.67s/it]\u001b[A\n",
            "Iteration:   7% 10/140 [02:46<36:05, 16.65s/it]\u001b[A\n",
            "Iteration:   8% 11/140 [03:03<35:48, 16.65s/it]\u001b[A\n",
            "Iteration:   9% 12/140 [03:19<35:29, 16.64s/it]\u001b[A\n",
            "Iteration:   9% 13/140 [03:36<35:09, 16.61s/it]\u001b[A\n",
            "Iteration:  10% 14/140 [03:53<35:34, 16.94s/it]\u001b[A\n",
            "Iteration:  11% 15/140 [04:10<35:13, 16.91s/it]\u001b[A\n",
            "Iteration:  11% 16/140 [04:27<34:47, 16.83s/it]\u001b[A\n",
            "Iteration:  12% 17/140 [04:44<34:22, 16.77s/it]\u001b[A\n",
            "Iteration:  13% 18/140 [05:00<33:58, 16.71s/it]\u001b[A\n",
            "Iteration:  14% 19/140 [05:17<33:36, 16.67s/it]\u001b[A\n",
            "Iteration:  14% 20/140 [05:33<33:14, 16.62s/it]\u001b[A\n",
            "Iteration:  15% 21/140 [05:50<32:58, 16.62s/it]\u001b[A\n",
            "Iteration:  16% 22/140 [06:06<32:39, 16.61s/it]\u001b[A\n",
            "Iteration:  16% 23/140 [06:23<32:24, 16.62s/it]\u001b[A\n",
            "Iteration:  17% 24/140 [06:40<32:06, 16.61s/it]\u001b[A\n",
            "Iteration:  18% 25/140 [06:56<31:49, 16.61s/it]\u001b[A\n",
            "Iteration:  19% 26/140 [07:13<31:32, 16.60s/it]\u001b[A\n",
            "Iteration:  19% 27/140 [07:29<31:13, 16.58s/it]\u001b[A\n",
            "Iteration:  20% 28/140 [07:46<30:55, 16.57s/it]\u001b[A\n",
            "Iteration:  21% 29/140 [08:03<30:41, 16.59s/it]\u001b[A11/25/2021 17:37:03 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 17:37:05 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 17:37:05 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  21% 30/140 [08:21<31:18, 17.07s/it]\u001b[A\n",
            "Iteration:  22% 31/140 [08:37<30:49, 16.96s/it]\u001b[A\n",
            "Iteration:  23% 32/140 [08:54<30:26, 16.92s/it]\u001b[A\n",
            "Iteration:  24% 33/140 [09:11<30:04, 16.86s/it]\u001b[A\n",
            "Iteration:  24% 34/140 [09:28<29:38, 16.78s/it]\u001b[A\n",
            "Iteration:  25% 35/140 [09:44<29:18, 16.75s/it]\u001b[A\n",
            "Iteration:  26% 36/140 [10:01<28:57, 16.70s/it]\u001b[A\n",
            "Iteration:  26% 37/140 [10:17<28:36, 16.66s/it]\u001b[A\n",
            "Iteration:  27% 38/140 [10:34<28:18, 16.65s/it]\u001b[A\n",
            "Iteration:  28% 39/140 [10:51<28:04, 16.67s/it]\u001b[A\n",
            "Iteration:  29% 40/140 [11:07<27:47, 16.67s/it]\u001b[A\n",
            "Iteration:  29% 41/140 [11:24<27:31, 16.68s/it]\u001b[A\n",
            "Iteration:  30% 42/140 [11:43<28:31, 17.46s/it]\u001b[A\n",
            "Iteration:  31% 43/140 [12:00<27:59, 17.31s/it]\u001b[A\n",
            "Iteration:  31% 44/140 [12:17<27:25, 17.14s/it]\u001b[A\n",
            "Iteration:  32% 45/140 [12:34<26:55, 17.01s/it]\u001b[A\n",
            "Iteration:  33% 46/140 [12:51<26:30, 16.92s/it]\u001b[A\n",
            "Iteration:  34% 47/140 [13:07<26:08, 16.86s/it]\u001b[A\n",
            "Iteration:  34% 48/140 [13:24<25:48, 16.84s/it]\u001b[A\n",
            "Iteration:  35% 49/140 [13:41<25:27, 16.79s/it]\u001b[A\n",
            "Iteration:  36% 50/140 [13:58<25:14, 16.83s/it]\u001b[A\n",
            "Iteration:  36% 51/140 [14:14<24:56, 16.81s/it]\u001b[A\n",
            "Iteration:  37% 52/140 [14:31<24:37, 16.79s/it]\u001b[A\n",
            "Iteration:  38% 53/140 [14:48<24:19, 16.78s/it]\u001b[A\n",
            "Iteration:  39% 54/140 [15:05<24:05, 16.80s/it]\u001b[A\n",
            "Iteration:  39% 55/140 [15:21<23:44, 16.76s/it]\u001b[A\n",
            "Iteration:  40% 56/140 [15:38<23:24, 16.72s/it]\u001b[A\n",
            "Iteration:  41% 57/140 [15:55<23:07, 16.71s/it]\u001b[A\n",
            "Iteration:  41% 58/140 [16:11<22:50, 16.72s/it]\u001b[A\n",
            "Iteration:  42% 59/140 [16:28<22:33, 16.70s/it]\u001b[A\n",
            "Iteration:  43% 60/140 [16:45<22:15, 16.70s/it]\u001b[A\n",
            "Iteration:  44% 61/140 [17:01<21:58, 16.68s/it]\u001b[A\n",
            "Iteration:  44% 62/140 [17:18<21:42, 16.70s/it]\u001b[A\n",
            "Iteration:  45% 63/140 [17:35<21:23, 16.67s/it]\u001b[A\n",
            "Iteration:  46% 64/140 [17:51<21:07, 16.67s/it]\u001b[A\n",
            "Iteration:  46% 65/140 [18:08<20:50, 16.67s/it]\u001b[A\n",
            "Iteration:  47% 66/140 [18:25<20:34, 16.68s/it]\u001b[A\n",
            "Iteration:  48% 67/140 [18:42<20:16, 16.67s/it]\u001b[A\n",
            "Iteration:  49% 68/140 [18:58<20:02, 16.70s/it]\u001b[A\n",
            "Iteration:  49% 69/140 [19:15<19:47, 16.73s/it]\u001b[A\n",
            "Iteration:  50% 70/140 [19:32<19:29, 16.70s/it]\u001b[A\n",
            "Iteration:  51% 71/140 [19:48<19:12, 16.71s/it]\u001b[A\n",
            "Iteration:  51% 72/140 [20:05<18:56, 16.72s/it]\u001b[A\n",
            "Iteration:  52% 73/140 [20:22<18:40, 16.72s/it]\u001b[A\n",
            "Iteration:  53% 74/140 [20:39<18:24, 16.73s/it]\u001b[A\n",
            "Iteration:  54% 75/140 [20:55<18:06, 16.71s/it]\u001b[A\n",
            "Iteration:  54% 76/140 [21:12<17:49, 16.71s/it]\u001b[A\n",
            "Iteration:  55% 77/140 [21:29<17:31, 16.69s/it]\u001b[A\n",
            "Iteration:  56% 78/140 [21:45<17:14, 16.69s/it]\u001b[A\n",
            "Iteration:  56% 79/140 [22:02<16:58, 16.70s/it]\u001b[A11/25/2021 17:51:03 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 17:51:03 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 17:51:03 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:05,  9.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:18<00:56,  9.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:47,  9.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:37<00:37,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:47<00:28,  9.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:56<00:18,  9.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:06<00:09,  9.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:13<00:00,  9.23s/it]\n",
            "11/25/2021 17:52:17 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 17:52:17 - INFO - trainer -     intent_acc = 0.97\n",
            "11/25/2021 17:52:17 - INFO - trainer -     loss = 0.20595893170684576\n",
            "11/25/2021 17:52:17 - INFO - trainer -     sementic_frame_acc = 0.864\n",
            "11/25/2021 17:52:17 - INFO - trainer -     slot_f1 = 0.9613259668508287\n",
            "11/25/2021 17:52:17 - INFO - trainer -     slot_precision = 0.9560439560439561\n",
            "11/25/2021 17:52:17 - INFO - trainer -     slot_recall = 0.9666666666666667\n",
            "11/25/2021 17:52:17 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 17:52:18 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 17:52:18 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  57% 80/140 [23:34<39:20, 39.34s/it]\u001b[A\n",
            "Iteration:  58% 81/140 [23:51<32:04, 32.61s/it]\u001b[A\n",
            "Iteration:  59% 82/140 [24:08<26:58, 27.90s/it]\u001b[A\n",
            "Iteration:  59% 83/140 [24:25<23:20, 24.56s/it]\u001b[A\n",
            "Iteration:  60% 84/140 [24:42<20:43, 22.21s/it]\u001b[A\n",
            "Iteration:  61% 85/140 [24:58<18:50, 20.56s/it]\u001b[A\n",
            "Iteration:  61% 86/140 [25:15<17:27, 19.39s/it]\u001b[A\n",
            "Iteration:  62% 87/140 [25:32<16:25, 18.59s/it]\u001b[A\n",
            "Iteration:  63% 88/140 [25:48<15:38, 18.04s/it]\u001b[A\n",
            "Iteration:  64% 89/140 [26:05<15:00, 17.65s/it]\u001b[A\n",
            "Iteration:  64% 90/140 [26:22<14:29, 17.40s/it]\u001b[A\n",
            "Iteration:  65% 91/140 [26:39<14:01, 17.18s/it]\u001b[A\n",
            "Iteration:  66% 92/140 [26:55<13:38, 17.05s/it]\u001b[A\n",
            "Iteration:  66% 93/140 [27:12<13:16, 16.94s/it]\u001b[A\n",
            "Iteration:  67% 94/140 [27:29<12:55, 16.86s/it]\u001b[A\n",
            "Iteration:  68% 95/140 [27:45<12:36, 16.82s/it]\u001b[A\n",
            "Iteration:  69% 96/140 [28:02<12:18, 16.79s/it]\u001b[A\n",
            "Iteration:  69% 97/140 [28:19<12:02, 16.79s/it]\u001b[A\n",
            "Iteration:  70% 98/140 [28:36<11:45, 16.80s/it]\u001b[A\n",
            "Iteration:  71% 99/140 [28:53<11:29, 16.82s/it]\u001b[A\n",
            "Iteration:  71% 100/140 [29:10<11:13, 16.84s/it]\u001b[A\n",
            "Iteration:  72% 101/140 [29:26<10:55, 16.80s/it]\u001b[A\n",
            "Iteration:  73% 102/140 [29:43<10:36, 16.76s/it]\u001b[A\n",
            "Iteration:  74% 103/140 [30:00<10:20, 16.76s/it]\u001b[A\n",
            "Iteration:  74% 104/140 [30:16<10:03, 16.77s/it]\u001b[A\n",
            "Iteration:  75% 105/140 [30:33<09:46, 16.77s/it]\u001b[A\n",
            "Iteration:  76% 106/140 [30:50<09:29, 16.76s/it]\u001b[A\n",
            "Iteration:  76% 107/140 [31:07<09:12, 16.76s/it]\u001b[A\n",
            "Iteration:  77% 108/140 [31:24<08:56, 16.76s/it]\u001b[A\n",
            "Iteration:  78% 109/140 [31:40<08:38, 16.74s/it]\u001b[A\n",
            "Iteration:  79% 110/140 [31:58<08:28, 16.94s/it]\u001b[A\n",
            "Iteration:  79% 111/140 [32:14<08:10, 16.91s/it]\u001b[A\n",
            "Iteration:  80% 112/140 [32:31<07:51, 16.84s/it]\u001b[A\n",
            "Iteration:  81% 113/140 [32:48<07:34, 16.84s/it]\u001b[A\n",
            "Iteration:  81% 114/140 [33:05<07:16, 16.80s/it]\u001b[A\n",
            "Iteration:  82% 115/140 [33:21<06:59, 16.78s/it]\u001b[A\n",
            "Iteration:  83% 116/140 [33:38<06:41, 16.75s/it]\u001b[A\n",
            "Iteration:  84% 117/140 [33:55<06:25, 16.78s/it]\u001b[A\n",
            "Iteration:  84% 118/140 [34:12<06:09, 16.81s/it]\u001b[A\n",
            "Iteration:  85% 119/140 [34:29<05:53, 16.81s/it]\u001b[A\n",
            "Iteration:  86% 120/140 [34:45<05:35, 16.77s/it]\u001b[A\n",
            "Iteration:  86% 121/140 [35:02<05:18, 16.77s/it]\u001b[A\n",
            "Iteration:  87% 122/140 [35:19<05:01, 16.77s/it]\u001b[A\n",
            "Iteration:  88% 123/140 [35:36<04:44, 16.74s/it]\u001b[A\n",
            "Iteration:  89% 124/140 [35:52<04:27, 16.73s/it]\u001b[A\n",
            "Iteration:  89% 125/140 [36:09<04:11, 16.78s/it]\u001b[A\n",
            "Iteration:  90% 126/140 [36:26<03:54, 16.75s/it]\u001b[A\n",
            "Iteration:  91% 127/140 [36:42<03:37, 16.73s/it]\u001b[A\n",
            "Iteration:  91% 128/140 [36:59<03:20, 16.68s/it]\u001b[A\n",
            "Iteration:  92% 129/140 [37:16<03:03, 16.67s/it]\u001b[A11/25/2021 18:06:16 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 18:06:18 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 18:06:18 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  93% 130/140 [37:34<02:50, 17.06s/it]\u001b[A\n",
            "Iteration:  94% 131/140 [37:50<02:32, 16.94s/it]\u001b[A\n",
            "Iteration:  94% 132/140 [38:07<02:14, 16.85s/it]\u001b[A\n",
            "Iteration:  95% 133/140 [38:24<01:57, 16.78s/it]\u001b[A\n",
            "Iteration:  96% 134/140 [38:40<01:40, 16.70s/it]\u001b[A\n",
            "Iteration:  96% 135/140 [38:57<01:23, 16.68s/it]\u001b[A\n",
            "Iteration:  97% 136/140 [39:13<01:06, 16.66s/it]\u001b[A\n",
            "Iteration:  98% 137/140 [39:30<00:49, 16.61s/it]\u001b[A\n",
            "Iteration:  99% 138/140 [39:46<00:33, 16.58s/it]\u001b[A\n",
            "Iteration:  99% 139/140 [40:03<00:16, 16.58s/it]\u001b[A\n",
            "Iteration: 100% 140/140 [40:19<00:00, 17.28s/it]\n",
            "Epoch:  80% 4/5 [2:41:04<40:26, 2426.29s/it]  \n",
            "Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/140 [00:16<38:18, 16.53s/it]\u001b[A\n",
            "Iteration:   1% 2/140 [00:32<37:55, 16.49s/it]\u001b[A\n",
            "Iteration:   2% 3/140 [00:49<37:42, 16.52s/it]\u001b[A\n",
            "Iteration:   3% 4/140 [01:05<37:20, 16.47s/it]\u001b[A\n",
            "Iteration:   4% 5/140 [01:22<37:05, 16.48s/it]\u001b[A\n",
            "Iteration:   4% 6/140 [01:38<36:46, 16.46s/it]\u001b[A\n",
            "Iteration:   5% 7/140 [01:55<36:34, 16.50s/it]\u001b[A\n",
            "Iteration:   6% 8/140 [02:11<36:14, 16.48s/it]\u001b[A\n",
            "Iteration:   6% 9/140 [02:28<35:55, 16.46s/it]\u001b[A\n",
            "Iteration:   7% 10/140 [02:44<35:38, 16.45s/it]\u001b[A\n",
            "Iteration:   8% 11/140 [03:01<35:22, 16.46s/it]\u001b[A\n",
            "Iteration:   9% 12/140 [03:17<35:05, 16.45s/it]\u001b[A\n",
            "Iteration:   9% 13/140 [03:36<36:40, 17.33s/it]\u001b[A\n",
            "Iteration:  10% 14/140 [03:53<35:54, 17.10s/it]\u001b[A\n",
            "Iteration:  11% 15/140 [04:10<35:14, 16.92s/it]\u001b[A\n",
            "Iteration:  11% 16/140 [04:26<34:39, 16.77s/it]\u001b[A\n",
            "Iteration:  12% 17/140 [04:42<34:12, 16.69s/it]\u001b[A\n",
            "Iteration:  13% 18/140 [04:59<33:45, 16.60s/it]\u001b[A\n",
            "Iteration:  14% 19/140 [05:15<33:22, 16.55s/it]\u001b[A\n",
            "Iteration:  14% 20/140 [05:32<33:02, 16.52s/it]\u001b[A\n",
            "Iteration:  15% 21/140 [05:48<32:45, 16.51s/it]\u001b[A\n",
            "Iteration:  16% 22/140 [06:05<32:26, 16.50s/it]\u001b[A\n",
            "Iteration:  16% 23/140 [06:21<32:08, 16.48s/it]\u001b[A\n",
            "Iteration:  17% 24/140 [06:38<31:51, 16.48s/it]\u001b[A\n",
            "Iteration:  18% 25/140 [06:54<31:37, 16.50s/it]\u001b[A\n",
            "Iteration:  19% 26/140 [07:11<31:18, 16.48s/it]\u001b[A\n",
            "Iteration:  19% 27/140 [07:27<31:01, 16.48s/it]\u001b[A\n",
            "Iteration:  20% 28/140 [07:44<30:48, 16.51s/it]\u001b[A\n",
            "Iteration:  21% 29/140 [08:00<30:40, 16.58s/it]\u001b[A\n",
            "Iteration:  21% 30/140 [08:17<30:25, 16.60s/it]\u001b[A\n",
            "Iteration:  22% 31/140 [08:34<30:09, 16.60s/it]\u001b[A\n",
            "Iteration:  23% 32/140 [08:50<29:55, 16.62s/it]\u001b[A\n",
            "Iteration:  24% 33/140 [09:07<29:34, 16.59s/it]\u001b[A\n",
            "Iteration:  24% 34/140 [09:23<29:14, 16.55s/it]\u001b[A\n",
            "Iteration:  25% 35/140 [09:40<28:56, 16.54s/it]\u001b[A\n",
            "Iteration:  26% 36/140 [09:56<28:42, 16.56s/it]\u001b[A\n",
            "Iteration:  26% 37/140 [10:13<28:24, 16.54s/it]\u001b[A\n",
            "Iteration:  27% 38/140 [10:29<28:04, 16.51s/it]\u001b[A\n",
            "Iteration:  28% 39/140 [10:46<27:47, 16.51s/it]\u001b[A11/25/2021 18:20:06 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 18:20:06 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 18:20:06 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:05,  9.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:18<00:56,  9.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:46,  9.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:37<00:37,  9.41s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:47<00:28,  9.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:56<00:18,  9.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:06<00:09,  9.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:13<00:00,  9.22s/it]\n",
            "11/25/2021 18:21:19 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 18:21:19 - INFO - trainer -     intent_acc = 0.978\n",
            "11/25/2021 18:21:19 - INFO - trainer -     loss = 0.20111101679503918\n",
            "11/25/2021 18:21:19 - INFO - trainer -     sementic_frame_acc = 0.884\n",
            "11/25/2021 18:21:19 - INFO - trainer -     slot_f1 = 0.9647743813682678\n",
            "11/25/2021 18:21:19 - INFO - trainer -     slot_precision = 0.9605797101449275\n",
            "11/25/2021 18:21:19 - INFO - trainer -     slot_recall = 0.9690058479532164\n",
            "11/25/2021 18:21:19 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 18:21:21 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 18:21:21 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  29% 40/140 [12:18<1:05:08, 39.09s/it]\u001b[A\n",
            "Iteration:  29% 41/140 [12:36<54:22, 32.96s/it]  \u001b[A\n",
            "Iteration:  30% 42/140 [12:53<45:47, 28.04s/it]\u001b[A\n",
            "Iteration:  31% 43/140 [13:09<39:43, 24.57s/it]\u001b[A\n",
            "Iteration:  31% 44/140 [13:26<35:26, 22.16s/it]\u001b[A\n",
            "Iteration:  32% 45/140 [13:43<32:29, 20.52s/it]\u001b[A\n",
            "Iteration:  33% 46/140 [13:59<30:16, 19.32s/it]\u001b[A\n",
            "Iteration:  34% 47/140 [14:16<28:37, 18.47s/it]\u001b[A\n",
            "Iteration:  34% 48/140 [14:32<27:25, 17.89s/it]\u001b[A\n",
            "Iteration:  35% 49/140 [14:49<26:29, 17.47s/it]\u001b[A\n",
            "Iteration:  36% 50/140 [15:05<25:45, 17.18s/it]\u001b[A\n",
            "Iteration:  36% 51/140 [15:22<25:10, 16.97s/it]\u001b[A\n",
            "Iteration:  37% 52/140 [15:38<24:43, 16.86s/it]\u001b[A\n",
            "Iteration:  38% 53/140 [15:55<24:19, 16.78s/it]\u001b[A\n",
            "Iteration:  39% 54/140 [16:11<23:56, 16.70s/it]\u001b[A\n",
            "Iteration:  39% 55/140 [16:28<23:34, 16.64s/it]\u001b[A\n",
            "Iteration:  40% 56/140 [16:44<23:15, 16.62s/it]\u001b[A\n",
            "Iteration:  41% 57/140 [17:01<23:01, 16.65s/it]\u001b[A\n",
            "Iteration:  41% 58/140 [17:18<22:41, 16.61s/it]\u001b[A\n",
            "Iteration:  42% 59/140 [17:34<22:22, 16.58s/it]\u001b[A\n",
            "Iteration:  43% 60/140 [17:51<22:07, 16.59s/it]\u001b[A\n",
            "Iteration:  44% 61/140 [18:07<21:48, 16.56s/it]\u001b[A\n",
            "Iteration:  44% 62/140 [18:24<21:30, 16.54s/it]\u001b[A\n",
            "Iteration:  45% 63/140 [18:40<21:15, 16.57s/it]\u001b[A\n",
            "Iteration:  46% 64/140 [18:57<20:58, 16.56s/it]\u001b[A\n",
            "Iteration:  46% 65/140 [19:13<20:41, 16.55s/it]\u001b[A\n",
            "Iteration:  47% 66/140 [19:30<20:25, 16.56s/it]\u001b[A\n",
            "Iteration:  48% 67/140 [19:47<20:10, 16.58s/it]\u001b[A\n",
            "Iteration:  49% 68/140 [20:03<19:54, 16.59s/it]\u001b[A\n",
            "Iteration:  49% 69/140 [20:20<19:37, 16.59s/it]\u001b[A\n",
            "Iteration:  50% 70/140 [20:36<19:19, 16.56s/it]\u001b[A\n",
            "Iteration:  51% 71/140 [20:53<19:02, 16.56s/it]\u001b[A\n",
            "Iteration:  51% 72/140 [21:09<18:45, 16.56s/it]\u001b[A\n",
            "Iteration:  52% 73/140 [21:26<18:27, 16.53s/it]\u001b[A\n",
            "Iteration:  53% 74/140 [21:42<18:13, 16.56s/it]\u001b[A\n",
            "Iteration:  54% 75/140 [21:59<17:57, 16.58s/it]\u001b[A\n",
            "Iteration:  54% 76/140 [22:16<17:43, 16.62s/it]\u001b[A\n",
            "Iteration:  55% 77/140 [22:33<17:27, 16.63s/it]\u001b[A\n",
            "Iteration:  56% 78/140 [22:49<17:10, 16.62s/it]\u001b[A\n",
            "Iteration:  56% 79/140 [23:06<16:53, 16.62s/it]\u001b[A\n",
            "Iteration:  57% 80/140 [23:22<16:36, 16.60s/it]\u001b[A\n",
            "Iteration:  58% 81/140 [23:39<16:21, 16.63s/it]\u001b[A\n",
            "Iteration:  59% 82/140 [23:56<16:05, 16.64s/it]\u001b[A\n",
            "Iteration:  59% 83/140 [24:12<15:46, 16.61s/it]\u001b[A\n",
            "Iteration:  60% 84/140 [24:29<15:28, 16.58s/it]\u001b[A\n",
            "Iteration:  61% 85/140 [24:45<15:10, 16.55s/it]\u001b[A\n",
            "Iteration:  61% 86/140 [25:02<14:54, 16.57s/it]\u001b[A\n",
            "Iteration:  62% 87/140 [25:18<14:35, 16.53s/it]\u001b[A\n",
            "Iteration:  63% 88/140 [25:35<14:18, 16.52s/it]\u001b[A\n",
            "Iteration:  64% 89/140 [25:51<14:02, 16.52s/it]\u001b[A11/25/2021 18:35:11 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 18:35:13 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 18:35:13 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration:  64% 90/140 [26:09<14:11, 17.03s/it]\u001b[A\n",
            "Iteration:  65% 91/140 [26:26<13:47, 16.89s/it]\u001b[A\n",
            "Iteration:  66% 92/140 [26:43<13:25, 16.79s/it]\u001b[A\n",
            "Iteration:  66% 93/140 [26:59<13:06, 16.74s/it]\u001b[A\n",
            "Iteration:  67% 94/140 [27:16<12:47, 16.68s/it]\u001b[A\n",
            "Iteration:  68% 95/140 [27:32<12:28, 16.63s/it]\u001b[A\n",
            "Iteration:  69% 96/140 [27:49<12:13, 16.67s/it]\u001b[A\n",
            "Iteration:  69% 97/140 [28:06<11:56, 16.66s/it]\u001b[A\n",
            "Iteration:  70% 98/140 [28:22<11:38, 16.62s/it]\u001b[A\n",
            "Iteration:  71% 99/140 [28:39<11:21, 16.62s/it]\u001b[A\n",
            "Iteration:  71% 100/140 [28:55<11:04, 16.62s/it]\u001b[A\n",
            "Iteration:  72% 101/140 [29:12<10:47, 16.59s/it]\u001b[A\n",
            "Iteration:  73% 102/140 [29:28<10:29, 16.56s/it]\u001b[A\n",
            "Iteration:  74% 103/140 [29:45<10:12, 16.56s/it]\u001b[A\n",
            "Iteration:  74% 104/140 [30:02<09:58, 16.62s/it]\u001b[A\n",
            "Iteration:  75% 105/140 [30:18<09:41, 16.60s/it]\u001b[A\n",
            "Iteration:  76% 106/140 [30:35<09:24, 16.59s/it]\u001b[A\n",
            "Iteration:  76% 107/140 [30:51<09:06, 16.57s/it]\u001b[A\n",
            "Iteration:  77% 108/140 [31:08<08:49, 16.56s/it]\u001b[A\n",
            "Iteration:  78% 109/140 [31:24<08:32, 16.55s/it]\u001b[A\n",
            "Iteration:  79% 110/140 [31:41<08:16, 16.55s/it]\u001b[A\n",
            "Iteration:  79% 111/140 [31:58<08:00, 16.58s/it]\u001b[A\n",
            "Iteration:  80% 112/140 [32:14<07:44, 16.58s/it]\u001b[A\n",
            "Iteration:  81% 113/140 [32:31<07:27, 16.57s/it]\u001b[A\n",
            "Iteration:  81% 114/140 [32:47<07:10, 16.56s/it]\u001b[A\n",
            "Iteration:  82% 115/140 [33:04<06:54, 16.59s/it]\u001b[A\n",
            "Iteration:  83% 116/140 [33:21<06:38, 16.60s/it]\u001b[A\n",
            "Iteration:  84% 117/140 [33:37<06:22, 16.63s/it]\u001b[A\n",
            "Iteration:  84% 118/140 [33:54<06:05, 16.63s/it]\u001b[A\n",
            "Iteration:  85% 119/140 [34:10<05:48, 16.60s/it]\u001b[A\n",
            "Iteration:  86% 120/140 [34:27<05:31, 16.58s/it]\u001b[A\n",
            "Iteration:  86% 121/140 [34:44<05:15, 16.58s/it]\u001b[A\n",
            "Iteration:  87% 122/140 [35:00<04:59, 16.62s/it]\u001b[A\n",
            "Iteration:  88% 123/140 [35:17<04:42, 16.60s/it]\u001b[A\n",
            "Iteration:  89% 124/140 [35:33<04:25, 16.57s/it]\u001b[A\n",
            "Iteration:  89% 125/140 [35:52<04:18, 17.22s/it]\u001b[A\n",
            "Iteration:  90% 126/140 [36:09<03:58, 17.01s/it]\u001b[A\n",
            "Iteration:  91% 127/140 [36:25<03:39, 16.86s/it]\u001b[A\n",
            "Iteration:  91% 128/140 [36:42<03:21, 16.75s/it]\u001b[A\n",
            "Iteration:  92% 129/140 [36:58<03:03, 16.68s/it]\u001b[A\n",
            "Iteration:  93% 130/140 [37:15<02:46, 16.62s/it]\u001b[A\n",
            "Iteration:  94% 131/140 [37:31<02:29, 16.57s/it]\u001b[A\n",
            "Iteration:  94% 132/140 [37:48<02:12, 16.57s/it]\u001b[A\n",
            "Iteration:  95% 133/140 [38:04<01:55, 16.56s/it]\u001b[A\n",
            "Iteration:  96% 134/140 [38:21<01:39, 16.62s/it]\u001b[A\n",
            "Iteration:  96% 135/140 [38:38<01:23, 16.68s/it]\u001b[A\n",
            "Iteration:  97% 136/140 [38:55<01:06, 16.74s/it]\u001b[A\n",
            "Iteration:  98% 137/140 [39:11<00:50, 16.70s/it]\u001b[A\n",
            "Iteration:  99% 138/140 [39:28<00:33, 16.64s/it]\u001b[A\n",
            "Iteration:  99% 139/140 [39:44<00:16, 16.62s/it]\u001b[A11/25/2021 18:49:03 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n",
            "11/25/2021 18:49:03 - INFO - trainer -     Num examples = 500\n",
            "11/25/2021 18:49:03 - INFO - trainer -     Batch size = 64\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 1/8 [00:09<01:06,  9.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 2/8 [00:18<00:56,  9.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38% 3/8 [00:28<00:46,  9.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 4/8 [00:37<00:37,  9.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62% 5/8 [00:47<00:28,  9.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  75% 6/8 [00:56<00:18,  9.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  88% 7/8 [01:06<00:09,  9.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 8/8 [01:13<00:00,  9.21s/it]\n",
            "11/25/2021 18:50:17 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 18:50:17 - INFO - trainer -     intent_acc = 0.978\n",
            "11/25/2021 18:50:17 - INFO - trainer -     loss = 0.19224121421575546\n",
            "11/25/2021 18:50:17 - INFO - trainer -     sementic_frame_acc = 0.884\n",
            "11/25/2021 18:50:17 - INFO - trainer -     slot_f1 = 0.9647743813682678\n",
            "11/25/2021 18:50:17 - INFO - trainer -     slot_precision = 0.9605797101449275\n",
            "11/25/2021 18:50:17 - INFO - trainer -     slot_recall = 0.9690058479532164\n",
            "11/25/2021 18:50:17 - INFO - transformers.configuration_utils -   Configuration saved in ./new_model/config.json\n",
            "11/25/2021 18:50:18 - INFO - transformers.modeling_utils -   Model weights saved in ./new_model/pytorch_model.bin\n",
            "11/25/2021 18:50:18 - INFO - trainer -   Saving model checkpoint to ./new_model/\n",
            "\n",
            "Iteration: 100% 140/140 [41:15<00:00, 17.68s/it]\n",
            "Epoch: 100% 5/5 [3:22:19<00:00, 2427.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYGWhu-zjuPy"
      },
      "source": [
        "Se evalúa el modelo (la data para pruebas es la misma que la utilizada en el trabajo de referencia)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7eUMNYK3oZy",
        "outputId": "8a4004f0-864c-41e7-b4ff-d8e7c489f19c"
      },
      "source": [
        " ! python3 main.py --task atis \\\n",
        "                  --model_type bert \\\n",
        "                  --model_dir atis_model \\\n",
        "                  --do_eval \\\n",
        "                  --model_dir ./new_model/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/25/2021 18:50:44 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/25/2021 18:50:44 - INFO - data_loader -   Loading features from cached file ./data/cached_train_atis_bert-base-uncased_50\n",
            "11/25/2021 18:50:44 - INFO - data_loader -   Loading features from cached file ./data/cached_dev_atis_bert-base-uncased_50\n",
            "11/25/2021 18:50:44 - INFO - data_loader -   Loading features from cached file ./data/cached_test_atis_bert-base-uncased_50\n",
            "11/25/2021 18:50:44 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/25/2021 18:50:44 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"atis\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/25/2021 18:50:44 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/25/2021 18:50:49 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing JointBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing JointBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "11/25/2021 18:50:49 - WARNING - transformers.modeling_utils -   Some weights of JointBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "11/25/2021 18:50:49 - INFO - transformers.configuration_utils -   loading configuration file ./new_model/config.json\n",
            "11/25/2021 18:50:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"atis\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/25/2021 18:50:49 - INFO - transformers.modeling_utils -   loading weights file ./new_model/pytorch_model.bin\n",
            "11/25/2021 18:50:52 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing JointBERT.\n",
            "\n",
            "11/25/2021 18:50:52 - INFO - transformers.modeling_utils -   All the weights of JointBERT were initialized from the model checkpoint at ./new_model/.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use JointBERT for predictions without further training.\n",
            "11/25/2021 18:50:52 - INFO - trainer -   ***** Model Loaded *****\n",
            "11/25/2021 18:50:52 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "11/25/2021 18:50:52 - INFO - trainer -     Num examples = 893\n",
            "11/25/2021 18:50:52 - INFO - trainer -     Batch size = 64\n",
            "Evaluating: 100% 14/14 [02:12<00:00,  9.48s/it]\n",
            "11/25/2021 18:53:05 - INFO - trainer -   ***** Eval results *****\n",
            "11/25/2021 18:53:05 - INFO - trainer -     intent_acc = 0.975363941769317\n",
            "11/25/2021 18:53:05 - INFO - trainer -     loss = 0.2689127568155527\n",
            "11/25/2021 18:53:05 - INFO - trainer -     sementic_frame_acc = 0.8533034714445689\n",
            "11/25/2021 18:53:05 - INFO - trainer -     slot_f1 = 0.9463157894736842\n",
            "11/25/2021 18:53:05 - INFO - trainer -     slot_precision = 0.9426773855295352\n",
            "11/25/2021 18:53:05 - INFO - trainer -     slot_recall = 0.9499823881648468\n"
          ]
        }
      ]
    }
  ]
}