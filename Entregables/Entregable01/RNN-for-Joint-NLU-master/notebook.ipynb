{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"notebook.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jXH-dFxty8Hc"},"source":["# Ejecución de modelo base\n","\n","En este notebook se ha seleccionado como base el trabajo presentado por Bing Liu y Ian Lane denominado Attention-Based Recurrent Neural Network Models for Joint Intent Detection\n","and Slot Filling: https://arxiv.org/pdf/1609.01454.pdf"]},{"cell_type":"markdown","metadata":{"id":"Aeun0YXizAJX"},"source":["## 1. Librerías a utilizar"]},{"cell_type":"code","metadata":{"id":"jzeTuLVNV0Nv","executionInfo":{"status":"ok","timestamp":1636070850756,"user_tz":300,"elapsed":695,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["import json\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import random\n","import numpy as np\n","from collections import Counter\n","import pickle\n","%matplotlib inline"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"kmLtfYvSV0N0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636070854303,"user_tz":300,"elapsed":462,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"8eb3f934-cd44-4a8b-fe12-6cfbbbef1671"},"source":["# Se verifica si es que el soporte de CUDA está disponible (para utilizar la GPU\n","# en el cómputo de tensores)\n","USE_CUDA = torch.cuda.is_available()\n","USE_CUDA"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"EW6nzfcsV0N1","executionInfo":{"status":"ok","timestamp":1636070857148,"user_tz":300,"elapsed":551,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se define función para convertir la sequencia de texto a índices en formato de\n","# tensor con soporte de CUDA\n","def prepare_sequence(seq, to_ix):\n","  # Crea una lista a partir de una secuencia. Para cada palabra de la secuencia \n","  # asigna un índice de acuerdo al diccionario \"to_ix\", ya sea que pertenece o \n","  # no (token desconocido <UNK>)\n","  idxs = list(map(lambda w: to_ix[w] if w in to_ix.keys() else to_ix[\"<UNK>\"], seq))\n","  # Convierte la lista en tensor con soporte de CUDA (si está disponible)\n","  tensor = Variable(torch.LongTensor(idxs)).cuda() if USE_CUDA else Variable(torch.LongTensor(idxs))\n","  return tensor\n","\n","# Se define función para obtener los elementos dentro de las listas de una tupla\n","flatten = lambda l: [item for sublist in l for item in sublist]"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7eJEYcbV0N2"},"source":["## 2. Carga de los datos y preprocesamiento"]},{"cell_type":"markdown","metadata":{"id":"cwZyaaxQzj6a"},"source":["El conjunto de entrenamiento se obtiene a partir del siguiente repositorio: https://github.com/yvchen/JointSLU/tree/master/data"]},{"cell_type":"code","metadata":{"id":"idnTabKO1JIZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636070860474,"user_tz":300,"elapsed":523,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"9fe205f4-9d93-4fde-c746-df6533e7e4f2"},"source":["# Obtenemos únicamente el archivo que se utilizará\n","!curl --remote-name -H --location https://raw.githubusercontent.com/yvchen/JointSLU/master/data/atis-2.train.w-intent.iob"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  789k  100  789k    0     0  3670k      0 --:--:-- --:--:-- --:--:-- 3670k\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"gOg6ptxIV0N2","executionInfo":{"status":"ok","timestamp":1636070863021,"user_tz":300,"elapsed":2,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Cuando se ejecuta en un entorno local indicar correctamente el path general \n","# del proyecto:\n","# path = r'G:\\Mi unidad\\CLASES\\PUCP\\2.Clases\\Ciclo-II-DL\\Proyecto-DL\\JoinIntentDetectionSlotFilling\\Entregables\\Entregable01\\RNN-for-Joint-NLU-master'\n","# train = open(path+\"\\\\\"+\"\\data\\\\atis-2.train.w-intent.iob\",\"r\").readlines()\n","\n","# Se lee la información del archivo con el corpus de ATIS\n","train = open('atis-2.train.w-intent.iob', 'r').readlines()\n","# Se eliminan los saltos de línea al final de la oración\n","train = [t[:-1] for t in train]\n","# Se obtiene la secuencia de entrada (oraciones en inglés), la secuencia de \n","# salida (secuencia de slots) y la intención relacionada a la secuencia\n","train = [[t.split('\\t')[0].split(' '), t.split('\\t')[1].split(' ')[:-1], t.split('\\t')[1].split(' ')[-1]] for t in train]\n","# Se retiran los tokens de inicio y fin en la secuencia de entrada, el token de \n","# inicio en la secuencia de salida (ya que se encuentra desfasada una posición \n","# respecto a la entrada)\n","train = [[t[0][1:-1],t[1][1:],t[2]] for t in train]"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"rqx2iX5By0zz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636070865411,"user_tz":300,"elapsed":3,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"0b858c50-0a1e-40f5-b642-5ab1ede8d269"},"source":["train[0]"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['i',\n","  'want',\n","  'to',\n","  'fly',\n","  'from',\n","  'baltimore',\n","  'to',\n","  'dallas',\n","  'round',\n","  'trip'],\n"," ['O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-fromloc.city_name',\n","  'O',\n","  'B-toloc.city_name',\n","  'B-round_trip',\n","  'I-round_trip'],\n"," 'atis_flight']"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"JrJuooGFV0N3","executionInfo":{"status":"ok","timestamp":1636070866934,"user_tz":300,"elapsed":2,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se obtiene las tuplas de las secuencias de entrada, salida y las intenciones \n","# por separado\n","seq_in, seq_out, intent = list(zip(*train))"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"vbbrItN3V0N3","executionInfo":{"status":"ok","timestamp":1636070868937,"user_tz":300,"elapsed":2,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se conforma el vocabulario de las palabras, las etiquetas de los slots y las \n","# etiquetas de las intenciones\n","vocab = set(flatten(seq_in))\n","slot_tag = set(flatten(seq_out))\n","intent_tag = set(intent)"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"o4BhYgIcV0N4","executionInfo":{"status":"ok","timestamp":1636070871373,"user_tz":300,"elapsed":572,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se establece el tamaño máximo de la secuencia\n","LENGTH = 50"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"WNJfftp6V0N4","executionInfo":{"status":"ok","timestamp":1636070873338,"user_tz":300,"elapsed":416,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se definen listas para almacenar las secuencias de entrada y salida luego del\n","# preprocesamiento para añadir tokens de fin de secuencia y para hacer padding\n","sin = []\n","sout = []"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"NNn_dJ5bV0N4","executionInfo":{"status":"ok","timestamp":1636070875213,"user_tz":300,"elapsed":1,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se añade nuevamente el token de fin de secuencia (<EOS>) y se hace padding\n","# hasta completar el tamaño máximo de secuencia\n","for i in range(len(seq_in)):\n","  # Secuencia de entrada\n","  temp = seq_in[i]\n","  if len(temp)<LENGTH:\n","    # Añade el token de fin de secuencia\n","    temp.append('<EOS>')\n","    while len(temp)<LENGTH:\n","      # Completa con token de padding hasta completar tamaño máximo de secuencia\n","      temp.append('<PAD>')\n","  else:\n","    # Trunca la secuencia en el tamaño máximo\n","    temp = temp[:LENGTH]\n","    # Reemplaza el último elemento por el token de fin de secuencia\n","    temp[-1]='<EOS>'\n","  sin.append(temp)\n","  \n","  # Secuencia de salida\n","  temp = seq_out[i]\n","  if len(temp)<LENGTH:\n","    while len(temp)<LENGTH:\n","      # Completa con token de padding hasta completar tamaño máximo de secuencia\n","      temp.append('<PAD>')\n","  else:\n","    # Trunca la secuencia en el tamaño máximo\n","    temp = temp[:LENGTH]\n","    # Reemplaza el último elemento por el token de fin de secuencia\n","    temp[-1]='<EOS>'\n","  sout.append(temp)"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"UcaKGEd6V0N5","executionInfo":{"status":"ok","timestamp":1636070877534,"user_tz":300,"elapsed":544,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se define un diccionario para mapear las palabras a índices\n","word2index = {'<PAD>': 0, '<UNK>':1, '<SOS>':2, '<EOS>':3}\n","for token in vocab:\n","  if token not in word2index.keys():\n","    word2index[token]=len(word2index)\n","\n","# Se invierte el diccionario (para mapear los índices a palabras)\n","index2word = {v:k for k,v in word2index.items()}\n","\n","# Se define un diccionario para mapear las etiquetas de slots a índices\n","tag2index = {'<PAD>' : 0}\n","for tag in slot_tag:\n","  if tag not in tag2index.keys():\n","    tag2index[tag] = len(tag2index)\n","\n","# Se invierte el diccionario (para mapear los índices a etiquetas de palabras)\n","index2tag = {v:k for k,v in tag2index.items()}\n","\n","# Se define un diccionario para mapear las etiquetas de intenciones a índices\n","intent2index={}\n","for ii in intent_tag:\n","  if ii not in intent2index.keys():\n","    intent2index[ii] = len(intent2index)\n","\n","# Se invierte el diccionario (para mapear los índices a etiquetas de intenciones)\n","index2intent = {v:k for k,v in intent2index.items()}"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"uxvkvDXTV0N5","executionInfo":{"status":"ok","timestamp":1636070881040,"user_tz":300,"elapsed":417,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se reconstruye una lista general con las listas de secuencias de entrada, \n","# salida y las intenciones\n","train = list(zip(sin, sout, intent))"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLA8jfqMV0N5","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1636070882961,"user_tz":300,"elapsed":3,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"d38988b4-0db1-48a8-a7c1-168a70b38088"},"source":["train[0][2]"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'atis_flight'"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"aehAHe-qV0N6","executionInfo":{"status":"ok","timestamp":1636070885569,"user_tz":300,"elapsed":939,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se define una lista vacía para almacenar los tensores con soporte de CUDA \n","# correspondientes a las secuencias de entrada, salida y las intenciones\n","train_data=[]\n","\n","for tr in train:\n","  # Se usa la función \"prepare_sequence\" para obtener el tensor de entrada con\n","  # soporte de CUDA\n","  temp = prepare_sequence(tr[0], word2index)\n","  temp = temp.view(1,-1)\n","  # Se usa la función \"prepare_sequence\" para obtener el tensor de salida con\n","  # soporte de CUDA\n","  temp2 = prepare_sequence(tr[1], tag2index)\n","  temp2 = temp2.view(1,-1)\n","  # Se usa la función \"prepare_sequence\" para obtener el tensor de intención \n","  # con soporte de CUDA\n","  temp3 = Variable(torch.LongTensor([intent2index[tr[2]]])).cuda() if USE_CUDA else Variable(torch.LongTensor([intent2index[tr[2]]]))\n","  # Almacena los tensores en una lista\n","  train_data.append((temp, temp2, temp3))"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"C_A1ymkFV0N6","executionInfo":{"status":"ok","timestamp":1636070888263,"user_tz":300,"elapsed":509,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["# Se define una función para producir batches aleatorios del conjunto de \n","# entrenamiento \n","def getBatch(batch_size, train_data):\n","  random.shuffle(train_data)\n","  sindex = 0\n","  eindex = batch_size\n","  while eindex < len(train_data):\n","    batch = train_data[sindex:eindex]\n","    temp = eindex\n","    eindex = eindex + batch_size\n","    sindex = temp\n","    \n","    yield batch"],"execution_count":66,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OzNWzwPlV0N6"},"source":["## 3. Definición del Modelo\n","\n","El modelo a trabajar se basa en una Red Neuronal Recurrente con arquitectura Secuencia a Secuencia o seq2seq. Esta consta de un codificador o encoder que recibe la secuencia de entrada, y de un decodificador o decoder que obtiene la secuencia de salida y la intención correspondiente."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"OJru6PCDV0N6","executionInfo":{"status":"ok","timestamp":1636070897319,"user_tz":300,"elapsed":435,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["class Encoder(nn.Module):\n","  # Función de inicialización\n","  def __init__(self, input_size, embedding_size, hidden_size, batch_size=16, n_layers=1):\n","    super(Encoder, self).__init__()\n","    # Se inicializa el tamaño de la secuencia de entrada, el tamaño del vector \n","    # de embedding, el tamaño del vector de estado oculto, el número de capas y \n","    # el tamaño del batch\n","    self.input_size = input_size\n","    self.embedding_size = embedding_size\n","    self.hidden_size = hidden_size\n","    self.n_layers = n_layers\n","    self.batch_size=batch_size\n","    # Se inicializa la capa de embedding y la capa bidireccional LSTM\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, batch_first=True, bidirectional=True)\n","  \n","  # Función para inicializar los pesos\n","  def init_weights(self):\n","    self.embedding.weight.data.uniform_(-0.1, 0.1)\n","    # self.lstm.weight.data.\n","  \n","  # Función para inicializar con zeros los vectores de estado oculto y de contexto\n","  def init_hidden(self, input):\n","    hidden = Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n","    context = Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n","    return (hidden, context)\n","  \n","  # Función para realizar el cómputo hacia adelante en el codificador\n","  def forward(self, input, input_masking):\n","    \"\"\"\n","    input : Tensor de entrada\n","    input_masking : Tensor de entrada enmascarado para los tokens padding\n","    \"\"\"\n","    # Se inicializan los vectores de estado oculto y de contexto\n","    self.hidden = self.init_hidden(input)\n","    # La secuencia de entrada pasa a través de la capa de embedding y se \n","    # transforma en vector\n","    embedded = self.embedding(input)\n","    # Se calcula la salida y los vectores de estado oculto y de contexto a \n","    # partir del vector de embedding de la secuencia de entrada\n","    output, self.hidden = self.lstm(embedded, self.hidden)\n","    # Vector de salida con el tamaño real de la secuencia (sin padding)\n","    real_context=[]\n","    for i, o in enumerate(output):\n","      real_length = input_masking[i].data.tolist().count(0)\n","      real_context.append(o[real_length-1])\n","            \n","    return output, torch.cat(real_context).view(input.size(0),-1).unsqueeze(1)\n"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPlWktH7V0N7","executionInfo":{"status":"ok","timestamp":1636070934008,"user_tz":300,"elapsed":435,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["class Decoder(nn.Module):\n","  # Función de inicialización\n","  def __init__(self,slot_size,intent_size,embedding_size,hidden_size,batch_size=16,n_layers=1,dropout_p=0.1):\n","    super(Decoder, self).__init__()\n","    # Se inicializa el tamaño del vector de estado oculto, el número de slots, \n","    # el número de intenciones, el tamaño del vector \n","    # de embedding, el , el número de capas y \n","    # el tamaño del batch\n","    self.hidden_size = hidden_size\n","    self.slot_size = slot_size\n","    self.intent_size = intent_size\n","    self.n_layers = n_layers\n","    self.dropout_p = dropout_p\n","    self.embedding_size = embedding_size\n","    self.batch_size = batch_size\n","\n","    # Define the layers\n","    self.embedding = nn.Embedding(self.slot_size, self.embedding_size) #TODO encoder와 공유하도록 하고 학습되지 않게..\n","\n","    #self.dropout = nn.Dropout(self.dropout_p)\n","    self.lstm = nn.LSTM(self.embedding_size+self.hidden_size*2, self.hidden_size, self.n_layers, batch_first=True)\n","    self.attn = nn.Linear(self.hidden_size,self.hidden_size) # Attention\n","    self.slot_out = nn.Linear(self.hidden_size*2, self.slot_size)\n","    self.intent_out = nn.Linear(self.hidden_size*2,self.intent_size)\n","    \n","  def init_weights(self):\n","        self.embedding.weight.data.uniform_(-0.1, 0.1)\n","        #self.out.bias.data.fill_(0)\n","        #self.out.weight.data.uniform_(-0.1, 0.1)\n","        #self.lstm.weight.data.\n","    \n","  def Attention(self, hidden, encoder_outputs, encoder_maskings):\n","        \"\"\"\n","        hidden : 1,B,D\n","        encoder_outputs : B,T,D\n","        encoder_maskings : B,T # ByteTensor\n","        \"\"\"\n","        \n","        hidden = hidden.squeeze(0).unsqueeze(2)  # 히든 : (1,배치,차원) -> (배치,차원,1)\n","        \n","        batch_size = encoder_outputs.size(0) # B\n","        max_len = encoder_outputs.size(1) # T\n","        energies = self.attn(encoder_outputs.contiguous().view(batch_size*max_len,-1)) # B*T,D -> B*T,D\n","        energies = energies.view(batch_size,max_len,-1) # B,T,D (배치,타임,차원)\n","        attn_energies = energies.bmm(hidden).transpose(1,2) # B,T,D * B,D,1 --> B,1,T\n","        attn_energies = attn_energies.squeeze(1).masked_fill(encoder_maskings,-1e12) # PAD masking\n","        \n","        alpha = F.softmax(attn_energies) # B,T\n","        alpha = alpha.unsqueeze(1) # B,1,T\n","        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D => B,1,D\n","        \n","        return context # B,1,D\n","    \n","  def init_hidden(self,input):\n","        hidden = Variable(torch.zeros(self.n_layers*1, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2,input.size(0), self.hidden_size))\n","        context = Variable(torch.zeros(self.n_layers*1, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n","        return (hidden,context)\n","    \n","  def forward(self, input,context,encoder_outputs,encoder_maskings,training=True):\n","        \"\"\"\n","        input : B,L(length)\n","        enc_context : B,1,D\n","        \"\"\"\n","        # Get the embedding of the current input word\n","        embedded = self.embedding(input)\n","        hidden = self.init_hidden(input)\n","        decode=[]\n","        aligns = encoder_outputs.transpose(0,1)\n","        length = encoder_outputs.size(1)\n","        for i in range(length): # Input_sequence와 Output_sequence의 길이가 같기 때문..\n","            aligned = aligns[i].unsqueeze(1)# B,1,D\n","            _, hidden = self.lstm(torch.cat((embedded,context,aligned),2), hidden) # input, context, aligned encoder hidden, hidden\n","            \n","            # for Intent Detection\n","            if i==0: \n","                intent_hidden = hidden[0].clone() \n","                intent_context = self.Attention(intent_hidden, encoder_outputs,encoder_maskings) \n","                concated = torch.cat((intent_hidden,intent_context.transpose(0,1)),2) # 1,B,D\n","                intent_score = self.intent_out(concated.squeeze(0)) # B,D\n","\n","            concated = torch.cat((hidden[0],context.transpose(0,1)),2)\n","            score = self.slot_out(concated.squeeze(0))\n","            softmaxed = F.log_softmax(score)\n","            decode.append(softmaxed)\n","            _,input = torch.max(softmaxed,1)\n","            embedded = self.embedding(input.unsqueeze(1))\n","            \n","            # 그 다음 Context Vector를 Attention으로 계산\n","            context = self.Attention(hidden[0], encoder_outputs,encoder_maskings) \n","        # 요고 주의! time-step을 column-wise concat한 후, reshape!!\n","        slot_scores = torch.cat(decode,1)\n","        return slot_scores.view(input.size(0)*length,-1), intent_score"],"execution_count":68,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nQuaG78rV0N8"},"source":["# Training"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"WQ6y_5IZV0N8","executionInfo":{"status":"ok","timestamp":1636070937739,"user_tz":300,"elapsed":408,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["LEARNING_RATE=0.001\n","EMBEDDING_SIZE=64\n","HIDDEN_SIZE=64\n","BATCH_SIZE=16\n","LENGTH=50\n","STEP_SIZE=10"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"VK7ygs1aV0N8","executionInfo":{"status":"ok","timestamp":1636070939982,"user_tz":300,"elapsed":2,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["encoder = Encoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE)\n","decoder = Decoder(len(tag2index),len(intent2index),len(tag2index)//3,HIDDEN_SIZE*2)\n","if USE_CUDA:\n","    encoder = encoder.cuda()\n","    decoder = decoder.cuda()\n","    \n","encoder.init_weights()\n","decoder.init_weights()\n","\n","loss_function_1 = nn.CrossEntropyLoss(ignore_index=0)\n","loss_function_2 = nn.CrossEntropyLoss()\n","enc_optim= optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n","dec_optim = optim.Adam(decoder.parameters(),lr=LEARNING_RATE)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_XVnGg0V0N8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636071872663,"user_tz":300,"elapsed":522595,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"61d772ce-3051-437b-9e80-d052132771b6"},"source":["losess_=[]\n","for step in range(STEP_SIZE):\n","    losses=[]\n","    for i, batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n","        x,y_1,y_2 = zip(*batch)\n","        x = torch.cat(x)\n","        tag_target = torch.cat(y_1)\n","        intent_target = torch.cat(y_2)\n","        x_mask = torch.cat([Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in x]).view(BATCH_SIZE,-1)\n","        y_1_mask = torch.cat([Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in tag_target]).view(BATCH_SIZE,-1)\n"," \n","        encoder.zero_grad()\n","        decoder.zero_grad()\n","\n","        output, hidden_c = encoder(x,x_mask)\n","        start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).cuda().transpose(1,0) if USE_CUDA else Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).transpose(1,0)\n","\n","        tag_score, intent_score = decoder(start_decode,hidden_c,output,x_mask)\n","\n","        loss_1 = loss_function_1(tag_score,tag_target.view(-1))\n","        loss_2 = loss_function_2(intent_score,intent_target)\n","\n","        loss = loss_1+loss_2\n","        losses.append(loss.data.cpu().numpy() if USE_CUDA else loss.data.numpy())\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm(encoder.parameters(), 5.0)\n","        torch.nn.utils.clip_grad_norm(decoder.parameters(), 5.0)\n","\n","        enc_optim.step()\n","        dec_optim.step()\n","\n","        if i % 100==0:\n","            print(\"Step\",step,\" epoch\",i,\" : \",np.mean(losses))\n","            losess_.append(np.mean(losses))\n","            losses=[]"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"]},{"output_type":"stream","name":"stdout","text":["Step 0  epoch 0  :  7.7977247\n","Step 0  epoch 100  :  3.575982\n","Step 0  epoch 200  :  2.511451\n","Step 1  epoch 0  :  2.2060168\n","Step 1  epoch 100  :  2.0416982\n","Step 1  epoch 200  :  1.8591514\n","Step 2  epoch 0  :  1.5543256\n","Step 2  epoch 100  :  1.3918931\n","Step 2  epoch 200  :  1.1043189\n","Step 3  epoch 0  :  0.7935283\n","Step 3  epoch 100  :  0.9071536\n","Step 3  epoch 200  :  0.83193743\n","Step 4  epoch 0  :  0.9652759\n","Step 4  epoch 100  :  0.6767602\n","Step 4  epoch 200  :  0.627241\n","Step 5  epoch 0  :  0.43303567\n","Step 5  epoch 100  :  0.5274046\n","Step 5  epoch 200  :  0.46831775\n","Step 6  epoch 0  :  0.38814506\n","Step 6  epoch 100  :  0.42927045\n","Step 6  epoch 200  :  0.40793678\n","Step 7  epoch 0  :  0.1731962\n","Step 7  epoch 100  :  0.3286417\n","Step 7  epoch 200  :  0.32569912\n","Step 8  epoch 0  :  0.18580785\n","Step 8  epoch 100  :  0.26348957\n","Step 8  epoch 200  :  0.26751268\n","Step 9  epoch 0  :  0.30198938\n","Step 9  epoch 100  :  0.23272507\n","Step 9  epoch 200  :  0.226545\n"]}]},{"cell_type":"code","metadata":{"id":"h6DpltobfBnT","executionInfo":{"status":"ok","timestamp":1636071975400,"user_tz":300,"elapsed":443,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["def plot_losses(loss):\n","    plt.plot(loss, label='train')\n","    plt.legend()\n","    plt.show()"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"RUcAnz4bfHJq","executionInfo":{"status":"ok","timestamp":1636071977130,"user_tz":300,"elapsed":4,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"a15cfdcf-0157-4bc9-c664-68eff74dfb0b"},"source":["plot_losses(losess_)"],"execution_count":76,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"cfcUSyFbV0N9"},"source":["# Test"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Yplv745CV0N9","executionInfo":{"status":"ok","timestamp":1636072017333,"user_tz":300,"elapsed":429,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["from data import *\n","from model import Encoder,Decoder"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-VgAh-_V0N9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636072034586,"user_tz":300,"elapsed":2994,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"435fee94-6a62-49ac-d38e-1e4ac4a9ca73"},"source":["_,word2index,tag2index,intent2index = preprocessing(\"atis-2.train.w-intent.iob\",60)"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["processed_data_path : /content/data/\n","Successfully load data. # of set : 4478 \n","# of vocab : 867, # of slot_tag : 120, # of intent_tag : 21\n","Preprocessing complete!\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"RcUdX18iV0N9","executionInfo":{"status":"ok","timestamp":1636072040644,"user_tz":300,"elapsed":547,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["index2tag = {v:k for k,v in tag2index.items()}\n","index2intent = {v:k for k,v in intent2index.items()}"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWGhDfKWV0N9","executionInfo":{"status":"ok","timestamp":1636072071620,"user_tz":300,"elapsed":962,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["encoder = Encoder(len(word2index),64,64)\n","decoder = Decoder(len(tag2index),len(intent2index),len(tag2index)//3,64*2)\n","\n","encoder.load_state_dict(torch.load('jointnlu-encoder.pkl'))\n","decoder.load_state_dict(torch.load('jointnlu-decoder.pkl'))\n","if USE_CUDA:\n","    encoder = encoder.cuda()\n","    decoder = decoder.cuda()"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppKBXPQhV0N-","executionInfo":{"status":"ok","timestamp":1636072085450,"user_tz":300,"elapsed":417,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}}},"source":["test = open(\"atis-2.train.w-intent.iob\",\"r\").readlines()\n","test = [t[:-1] for t in test]\n","test = [[t.split(\"\\t\")[0].split(\" \"),t.split(\"\\t\")[1].split(\" \")[:-1],t.split(\"\\t\")[1].split(\" \")[-1]] for t in test]\n","test = [[t[0][1:-1],t[1][1:],t[2]] for t in test]"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"qa0ADCUMV0N-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636072105219,"user_tz":300,"elapsed":420,"user":{"displayName":"Juan Carlos Alfredo Tovar Galarreta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipT7CBIrN_YOquNWl-4MtUJObdsxlOkLjsi3HZJQ=s64","userId":"03057704301879114088"}},"outputId":"8dd21778-1f52-4ba0-9404-97d933c5a683"},"source":["index = random.choice(range(len(test)))\n","test_raw = test[index][0]\n","test_in = prepare_sequence(test_raw,word2index)\n","test_mask = Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, test_in.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, test_in.data)))).view(1,-1)\n","start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*1])).cuda().transpose(1,0) if USE_CUDA else Variable(torch.LongTensor([[word2index['<SOS>']]*1])).transpose(1,0)\n","\n","output, hidden_c = encoder(test_in.unsqueeze(0),test_mask.unsqueeze(0))\n","tag_score, intent_score = decoder(start_decode,hidden_c,output,test_mask)\n","\n","v,i = torch.max(tag_score,1)\n","print(\"Input Sentence : \",*test[index][0])\n","print(\"Truth        : \",*test[index][1])\n","print(\"Prediction : \",*list(map(lambda ii:index2tag[ii],i.data.tolist())))\n","v,i = torch.max(intent_score,1)\n","print(\"Truth        : \",test[index][2])\n","print(\"Prediction : \",index2intent[i.data.tolist()[0]])"],"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Sentence :  i live in denver and i'd like to make a trip to pittsburgh\n","Truth        :  O O O B-fromloc.city_name O O O O O O O O B-toloc.city_name\n","Prediction :  I-today_relative B-stoploc.city_name B-stoploc.city_name B-stoploc.city_name B-stoploc.city_name B-stoploc.city_name B-stoploc.city_name B-return_date.month_name B-stoploc.city_name I-toloc.state_name I-arrive_time.time_relative I-arrive_time.time_relative I-arrive_time.time_relative\n","Truth        :  atis_flight\n","Prediction :  atis_airline#atis_flight_no\n"]},{"output_type":"stream","name":"stderr","text":["/content/model.py:94: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:937.)\n","  attn_energies = attn_energies.squeeze(1).masked_fill(encoder_maskings,-1e12) # PAD masking\n","/content/model.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  alpha = F.softmax(attn_energies) # B,T\n","/content/model.py:131: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmaxed = F.log_softmax(score)\n"]}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"tbOaNslmV0N-"},"source":["# TODO "]},{"cell_type":"markdown","metadata":{"id":"jifCJxzPV0N-"},"source":["* LSTM forget gate의 bias 1로 고정\n","* intent decoder의 attention을 독립적인 weight로 구성해보기\n","* log_softmax 안하고 그냥  crossentropy해보기"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"PPcfEk7xV0N-"},"source":[""],"execution_count":null,"outputs":[]}]}